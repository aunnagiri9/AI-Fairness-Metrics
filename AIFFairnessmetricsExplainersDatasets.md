# AIF360 Instructional Document

## Introduction to AIF360
AIF360 is an open-source Python library developed by IBM that provides tools for bias mitigation, fairness assessment, and transparency in AI systems. This document will guide you through the process of using AIF360 for your fairness-aware machine learning projects.


This Document Consists of the Algorithms and Fairness Metrics in AIF360

# Table of Contents

- [Algorithms](#algorithms)
  - [aif360.algorithms](#aif360algorithms)
- [Fairness Metrics](#fairness-metrics)
  - [aif360.metrics](#aif360metrics)
  - [aif360.metrics.utils](#aif360metricsutils)
- [Explainers](#explainers)
  - [aif360.explainers](#aif360explainers)
- [Datasets](#datasets)
  - [aif360.datasets](#aif360datasets)

## Algorithms

This section provides information about algorithms in AIF360.

### aif360.algorithms

#### 1. aif360.algorithms.Transformer
**Class**: `classaif360.algorithms.Transformer(**kwargs)`
**Description**:
- The Transformer class is an abstract base class that serves as the foundation for various preprocessing, in-processing, and post-processing algorithms in AIF360. It represents an abstraction for any process that takes a `dataset` as input and produces a new, modified dataset as output. 
- This class encapsulates common functionality and methods that are shared among different types of transformers.

**Intialization:**
- ***kwargs:* Algorithm-specific configuration parameters should be passed as keyword arguments when initializing a Transformer object. 
- These parameters are used to configure the behavior of specific algorithms derived from this base class.

Example of initializing a Transformer object:

```python
__init__(**kwargs)
```

Algorithm-specific configuration parameters should be passed here.

**Methods**:
- `fit`	
- `fit_predict`	
- `fit_transform`	
- `predict`	
- `transform`	


**Methods Explanation:**:

1. **`fit(dataset)`**: Train a model on the input.
    ```python
    fit(dataset)
    ```
    **Parameters**: `dataset` (*Dataset*) - Input Dataset.
    
    **Returns**: `Transformer` -  Returns self.

2. **`fit_predict`**: 
    - Train a model on the input and predict the labels.
    - Equivalent to calling `fit(dataset)` followed by `predict(dataset)`
    ```python
    fit_predict(dataset)
    ```
    **Parameters**: `dataset` (*Dataset*) - Input Dataset.
    
    **Returns**: `Dataset` – Output dataset (`metadata` should reflect the details of this transformation).

3. **`fit_transform`**: 
    - Train a model on the input and transform the dataset accordingly.
    - Equivalent to calling `fit(dataset)` followed by `transform(dataset)`.
    
    ```python
    fit_transform(dataset)
    ```
    **Parameters**: `dataset` (*Dataset*) - Input Dataset.
    
    **Returns**: `Dataset` – Output dataset (`metadata` should reflect the details of this transformation).

4. **`predict`**: Return a new dataset with labels predicted by running this Transformer on the input.
    ```python
    predict(dataset)
    ```
    **Parameters**: `dataset` (*Dataset*) - Input Dataset.
    
    **Returns**: `Dataset` – Output dataset (`metadata` should reflect the details of this transformation).

5. **`transform`**: 
    - Return a new dataset generated by running this Transformer on the input.
    - This function could return different `dataset.features`, `dataset.labels`, or both.
    ```python
    transform(dataset)
    ```
    **Parameters**: `dataset` (*Dataset*) - Input Dataset.
    
    **Returns**: `Dataset` – Output dataset (`metadata` should reflect the details of this transformation).

---
---


## Fairness Metrics

In this section, you'll find information about fairness metrics in AIF360.

### 1. aif360.metrics
1. DatasetMetric
2. BinaryLabelDatsetMetric
3. ClassificationMetric
4. SampleDistortionMetric
5. MDSSClassificatinMetric


#### 1. DatasetMetric
**Class**:`aif360.metrics.DatasetMetric`(*dataset, unprivileged_groups=None, privileged_groups=None*)
**Description**: Class for computing metrics based on one StructuredDataset.

**Initialization**:
```python
__init__(dataset, unprivileged_groups=None, privileged_groups=None)
```

**Parameters**:
- **`dataset`** (_StructuredDataset_) – A StructuredDataset.
- **`privileged_groups`** (_list(dict)_) – Privileged groups. Format is a list of `dicts` where the keys are `protected_attribute_names` and the values are values in `protected_attributes`. Each dict element describes a single group. 
- **`unprivileged_groups`** (_list(dict)_) – Unprivileged groups in the same format as `privileged_groups`.

**Raises**:
- **TypeError** – `dataset` must be a StructuredDataset type.
- **ValueError** – `privileged_groups` and `unprivileged_groups` must be disjoint.

**Examples**:
```python
from aif360.datasets import GermanDataset
german = GermanDataset()
u = [{'sex': 1, 'age': 1}, {'sex': 0}]
p = [{'sex': 1, 'age': 0}]
dm = DatasetMetric(german, unprivileged_groups=u, privileged_groups=p)
```

**Methods**:
- `difference`	
- `num_instances`	
- `ratio`	

**Methods Explanation**:
1. **`differnce`**:	Compute difference of the metric for unprivileged and privileged groups.
    ```python
    differnce(metric_fun)
    ```
    **Parameters**: `metric_fun` (*function*): A function that calculates the desired metric.
    
    **Returns**: The difference in the metric between unprivileged and privileged groups.
    
2. **`num_instances`**:	Compute the number of instances,𝑛, in the dataset conditioned on protected attributes if necessary.
    ```python
    num_instances(previleged=None)
    ```
    **Parameters**:
    - **`privileged`** (*bool, optional*) – Boolean prescribing whether to condition this metric on the `privileged_groups`, if `True`, or the `unprivileged_groups`, if `False`. Defaults to `None` meaning this metric is computed over the entire dataset.

    **Raises**:
    - **AttributeError** – `privileged_groups` or `unprivileged_groups` must be must be provided at initialization to condition on them.
    
    
3. **`ratio`**:	Computes the ratio of the metric for unprivileged and privileged groups.
    ```python
    ratio(metric_fun)
    ```
    **Parameters**: `metric_fun` (_function_) - A function that calculates the desired metric.
    
    **Returns**: The ratio of the metric between unprivileged and privileged groups.


#### 2. BinaryLabelDatasetMetric
**Class**:`aif360.metrics.BinaryLabelDatasetMetric`(_dataset, unprivileged_groups=None, privileged_groups=None_)
**Description**: Class for computing metrics based on a single `BinaryLabelDataset`.
**Initialization**:
```python
__init__(dataset, unprivileged_groups=None, privileged_groups=None)
```

**Parameters**:
- **`dataset`** (_StructuredDataset_) – A BinaryLabelDataset.
- **`privileged_groups`** (_list(dict)_) – Privileged groups. Format is a list of `dicts` where the keys are `protected_attribute_names` and the values are values in `protected_attributes`. Each dict element describes a single group.
- **`unprivileged_groups`** (_list(dict)_) – Unprivileged groups in the same format as `privileged_groups`.

**Raises**:
- **TypeError** – `dataset` must be a `BinaryLabelDataset` type.

**Examples**:
```python
from aif360.datasets import GermanDataset
german = GermanDataset()
u = [{'sex': 1, 'age': 1}, {'sex': 0}]
p = [{'sex': 1, 'age': 0}]
dm = DatasetMetric(german, unprivileged_groups=u, privileged_groups=p)
```

**Methods**:
- `base_rate`
- `consistency`	
- `difference`
- `disparate_impact`	
- `mean_difference`	
- `num_instances`
- `num_negatives`	
- `num_positives`	
- `ratio`
- `rich_subgroup`	
- `smoothed_empirical_differential_fairness`	
- `statistical_parity_difference`	

**Methods Explanation**:

1. **`base_rate`**(*privileged=None*): Compute the base rate, **𝑃𝑟(𝑌=1)=𝑃/(𝑃+𝑁)**, optionally conditioned on protected attributes.
   
   **Parameters**:- `privileged` (*bool, optional*) – Boolean prescribing whether to condition this metric on the `privileged_groups`, if True, or the `unprivileged_groups`, if `False`. Defaults to `None` meaning this metric is computed over the entire dataset.
   
   **Returns**:- `float` – Base rate (optionally conditioned).

2. **`consistency`**(*n_neighbors=5*): Individual fairness metric from [1] that measures how similar the labels are for similar instances.

    **Parameters**:- `n_neighbors` (int, optional) – Number of neighbors for the knn computation.
   **References**:
     - [1] R. Zemel, Y. Wu, K. Swersky, T. Pitassi, and C. Dwork, “Learning Fair Representations,” International Conference on Machine Learning, 2013.   

$$
1 - \frac{1}{n}\sum_{i=1}^n |\hat{y}_i -
\frac{1}{\mathrm{n_{neighbors}}} \sum_{j\in\mathcal{N}_{\mathrm{n_{neighbors}}}(x_i)} \hat{y}_j|
$$

  



3. **`disparate_impact`**: **𝑃𝑟(𝑌=1|𝐷=unprivileged)/𝑃𝑟(𝑌=1|𝐷=privileged)**.

4. **`mean_difference`**: Alias of `statistical_parity_difference()`.

5. **`num_negatives`**(*privileged=None*):Compute the number of negatives,optionally conditioned on protected attributes.

    **Parameters**:- `privileged` (bool, optional) – Boolean prescribing whether to condition this metric on the privileged_groups, if True, or the unprivileged_groups, if False. Defaults to None meaning this metric is computed over the entire dataset.
   
   **Raises**:- `AttributeError` – privileged_groups or unprivileged_groups must be provided at initialization to condition on them.

$$
N = \sum_{i=1}^n \mathbb{1}[y_i = 0]
$$


    
  

6. **`num_positives`**(*privileged=None*):Compute the number of positives,optionally conditioned on protected attributes.
   
   **Parameters**:- `privileged` (bool, optional) – Boolean prescribing whether to condition this metric on the privileged_groups, if True, or the unprivileged_groups, if False. Defaults to None meaning this metric is computed over the entire dataset.

    **Raises**:- `AttributeError` – privileged_groups or unprivileged_groups must be provided at initialization to condition on them.
$$
P = \sum_{i=1}^n \mathbb{1}[y_i = 1]
$$

7. **`rich_subgroup`**(*predictions, fairness_def='FP'*): Audit dataset with respect to rich subgroups defined by linear thresholds of sensitive attributes.
   
   **Parameters**:
     - `predictions` (hashable tuple) – Typically the labels attribute of a GerryFairClassifier.
     - `fairness_def` (str) – 'FP' or 'FN' for rich subgroup with respect to false positive or false negative rate.

    **Returns**:
     - The gamma disparity with respect to the fairness_def.
   
   **Examples**:
     - See examples/gerry_plots.ipynb.

8. **`Smoothed_empirical_differential_fairness`**(*concentration=1.0*): Smoothed EDF from [2].
   
   **Parameters**:- `concentration` (*float, optional*) – Concentration parameter for Dirichlet smoothing. Must be non-negative.
   
   **Examples**:
     - To use with non-binary protected attributes, the column must be converted to ordinal:

       ```python
       >>> mapping = {'Black': 0, 'White': 1, 'Asian-Pac-Islander': 2, 'Amer-Indian-Eskimo': 3, 'Other': 4}
       >>> def map_race(df):
       ...     df['race-num'] = df.race.map(mapping)
       ...     return df
       ...
       >>> adult = AdultDataset(protected_attribute_names=['sex', 'race-num'], privileged_classes=[['Male'], [1]], categorical_features=['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'native-country', 'race'], custom_preprocessing=map_race)
       >>> metric = BinaryLabelDatasetMetric(adult)
       >>> metric.smoothed_empirical_differential_fairness()
       1.7547611985549287
       ```
   - **References**:
     - [2] J. R. Foulds, R. Islam, K. N. Keya, and S. Pan, “An Intersectional Definition of Fairness,” arXiv preprint arXiv:1807.08362, 2018.

9. **`Statistical_parity_difference`**: **𝑃𝑟(𝑌=1|𝐷=unprivileged)−𝑃𝑟(𝑌=1|𝐷=privileged)**.




#### 3. ClassificationMetric

**Class**:`aif360.metrics.ClassificationMetric`(*dataset, classified_dataset, unprivileged_groups=None, privileged_groups=None*)

**Description**:
- Class for computing metrics based on two BinaryLabelDatasets.
- The first dataset is the original one and the second is the output of the classification transformer (or similar).

**Initialization**:


```python
__init__(dataset, classified_dataset, unprivileged_groups=None, privileged_groups=None)
```

**Parameters**:	
- `dataset` (*BinaryLabelDataset*) – Dataset containing ground-truth labels.
- `classified_dataset` (*BinaryLabelDataset*) – Dataset containing predictions.
- `privileged_groups` (*list(dict)*) – Privileged groups. Format is a list of dicts where the keys are `protected_attribute_names` and the values are values in `protected_attributes`. Each dict element describes a single group. See examples for more details.
- `unprivileged_groups` (*list(dict)*) – Unprivileged groups in the same format as privileged_groups.

**Raises**:	
- `TypeError` – `dataset` and `classified_dataset` must be BinaryLabelDataset types.


**Methods**:
1. **`accuracy(privileged=None)`**: Compute accuracy, which is the ratio of true positives and true negatives to the total number of examples.

     - 𝐴𝐶𝐶=(𝑇𝑃+𝑇𝑁)/(𝑃+𝑁)

    **Parameters**:	privileged (*bool, optional*) – Boolean prescribing whether to condition this metric on the `privileged_groups`, if `True`, or the `unprivileged_groups`, if `False`. Defaults to None meaning this metric is computed over the entire dataset.
    
    **Raises**:	`AttributeError` – `privileged_groups` or `unprivileged_groups` must be provided at initialization to condition on them.


2. **`average_abs_odds_difference()`**: Compute the average of the absolute difference in false positive rate (FPR) and true positive rate (TPR) between unprivileged and privileged groups. 

    >A value of 0 indicates equality of odds.

$$
\tfrac{1}{2}\left[|FPR_{D = \mathrm{unprivileged}} - FPR_{D = \mathrm{privileged}}|
+ |TPR_{D = \mathrm{unprivileged}} - TPR_{D = \mathrm{privileged}}|\right]
$$


    
    
3. **`average_odds_difference()`**: Compute the average of the difference in false positive rate (FPR) and true positive rate (TPR) between unprivileged and privileged groups.
    - Average of difference in FPR and TPR for unprivileged and privileged groups
    - A value of 0 indicates equality of odds.
    
$$
\tfrac{1}{2}\left[FPR_{D = \text{unprivileged}} - FPR_{D = \text{privileged}}
+ TPR_{D = \text{unprivileged}} - TPR_{D = \text{privileged}}\right]
$$


4. **`average_predictive_value_difference()`**: Compute the average of the difference in positive predictive value (PPV) and false omission rate (FOR) between unprivileged and privileged groups.
    - Average of difference in PPV and FOR for unprivileged and privileged groups
    - A value of 0 indicates equality of chance of success.

$$
\tfrac{1}{2}\left[(PPV_{D = \text{unprivileged}} - PPV_{D = \text{privileged}})
+ (FOR_{D = \text{unprivileged}} - FOR_{D = \text{privileged}})\right]
$$

       

5. **`between_all_groups_coefficient_of_variation()`**: Compute the between-group coefficient of variation using all combinations of groups based on protected attributes.
        The between-group coefficient of variation is the square root of two times the `between_all_groups_generalized_entropy_index()` with 𝛼=2.
    

6. **`between_all_groups_generalized_entropy_index(alpha=2)`**: Compute the between-group generalized entropy index using all combinations of groups based on protected attributes.

    **Parameters**:	`alpha` (*int*) – See `generalized_entropy_index()`.

7. **`between_all_groups_theil_index()`**: Compute the between-group Theil index using all combinations of groups based on protected attributes.
    - The between-group Theil index is the `between_all_groups_generalized_entropy_index()` with `𝛼=1`

8. **`between_group_coefficient_of_variation()`**: Compute the between-group coefficient of variation using only the privileged and unprivileged groups.
    - The between-group coefficient of variation is the square root of two times the     `between_group_generalized_entropy_index()` with    `𝛼=2`
    
9. **`between_group_generalized_entropy_index(alpha=2)`**: Compute the between-group generalized entropy index using only the privileged and unprivileged groups.
    - Between-group generalized entropy index that uses self.privileged_groups and self.unprivileged_groups as the only two groups. See _between_group_generalized_entropy_index().

    **Parameters**:	`alpha` (*int*) – See `generalized_entropy_index()`.
10. **`between_group_theil_index()`**: The between-group Theil index is the `between_group_generalized_entropy_index()` with `𝛼=1`

11. **`binary_confusion_matrix(privileged=None)`**: Compute the number of true positives, false positives, true negatives, and false negatives, optionally conditioned on protected attributes.

    **Parameters**:	`privileged` (*bool, optional*) – Boolean prescribing whether to condition this metric on the `privileged_groups`, if `True`, or the `unprivileged_groups`, if `False`. Defaults to None meaning this metric is computed over the entire dataset.
    
    **Returns**:	`dict` – Number of true positives, false positives, true negatives, false negatives (optionally conditioned).

12. **`coefficient_of_variation()`**: The coefficient of variation is the square root of two times the `generalized_entropy_index()` with `𝛼=2`

13. **`differential_fairness_bias_amplification(concentration=1.0)`**: Bias amplification is the difference in smoothed EDF between the classifier and the original dataset. Positive values mean the bias increased due to the classifier.
    
    **Parameters**:	`concentration` (*float, optional*) – Concentration parameter for Dirichlet smoothing. Must be non-negative.

14. **`disparate_impact()`**: Compute the disparate impact metric, which measures the difference in predicted positive outcomes between unprivileged and privileged groups.

$$
\frac{Pr(\hat{Y} = 1 | D = \text{unprivileged})}
{Pr(\hat{Y} = 1 | D = \text{privileged})}
$$


15. **`equal_opportunity_difference()`**: Compute the difference in true positive rates (TPR) between unprivileged and privileged groups, also known as equal opportunity difference.
    - Alias of true_positive_rate_difference() 

16. **`error_rate(privileged=None)`**: Compute the error rate, which is the ratio of false positives and false negatives to the total number of examples.
    - 𝐸𝑅𝑅=(𝐹𝑃+𝐹𝑁)/(𝑃+𝑁)
 
    **Parameters**:	`privileged` (*bool, optional*) – Boolean prescribing whether to condition this metric on the `privileged_groups`, if `True`, or the `unprivileged_groups`, if `False`. Defaults to `None` meaning this metric is computed over the entire dataset.
    
    **Raises**:	AttributeError – privileged_groups or unprivileged_groups must be provided at initialization to condition on them.
17. **`error_rate_difference()`**: Compute the difference in error rates between unprivileged and privileged groups.

$$
ERR_{D = \text{unprivileged}} - ERR_{D = \text{privileged}}
$$

18. **`error_rate_ratio()`**: Compute the ratio of error rates between unprivileged and privileged groups.
$$
\frac{ERR_{D = \text{unprivileged}}}{ERR_{D = \text{privileged}}}
$$

19. **`false_discovery_rate(privileged=None)`**: Compute the false discovery rate (FDR), which is the ratio of false positives to the total number of predicted positives.

    - 𝐹𝐷𝑅=𝐹𝑃/(𝑇𝑃+𝐹𝑃)
 

    **Parameters**:	`privileged` (*bool, optional*) – Boolean prescribing whether to condition this metric on the `privileged_groups`, if `True`, or the `unprivileged_groups`, if `False`. Defaults to `None` meaning this metric is computed over the entire dataset.
    
    **Raises**:	AttributeError – privileged_groups or unprivileged_groups must be provided at initialization to condition on them.

20. **`false_discovery_rate_difference()`**: Compute the difference in false discovery rates (FDR) between unprivileged and privileged groups.

$$
FDR_{D = \text{unprivileged}} - FDR_{D = \text{privileged}}
$$

21. **`false_discovery_rate_ratio()`**: Compute the ratio of false discovery rates (FDR) between unprivileged and privileged groups.
$$
\frac{FDR_{D = \text{unprivileged}}}{FDR_{D = \text{privileged}}}
$$



22. **`false_negative_rate(privileged=None)`**: Compute the false negative rate (FNR), which is the ratio of false negatives to the total number of actual positives.
    - 𝐹𝑁𝑅=𝐹𝑁/𝑃
 
    **Parameters**:	*privileged* (*bool, optional*) – Boolean prescribing whether to condition this metric on the `privileged_groups`, if `True`, or the `unprivileged_groups`, if `False`. Defaults to `None` meaning this metric is computed over the entire dataset.
    
    **Raises**:	`AttributeError` – privileged_groups or unprivileged_groups must be provided at initialization to condition on them.
23. **`false_negative_rate_difference()`**: Compute the difference in false negative rates (FNR) between unprivileged and privileged groups.

$$
FNR_{D = \text{unprivileged}} - FNR_{D = \text{privileged}}
$$

24. **`false_negative_rate_ratio()`**: Compute the ratio of false negative rates (FNR) between unprivileged and privileged groups.
$$
\frac{FNR_{D = \text{unprivileged}}}{FNR_{D = \text{privileged}}}
$$

25. **`false_omission_rate(privileged=None)`**: Compute the false omission rate (FOR), which is the ratio of false negatives to the total number of actual negatives.
    - 𝐹𝑂𝑅=𝐹𝑁/(𝑇𝑁+𝐹𝑁)
 
    **Parameters**:	`privileged` (*bool, optional*) – Boolean prescribing whether to condition this metric on the `privileged_groups`, if `True`, or the `unprivileged_groups`, if `False`. Defaults to `None` meaning this metric is computed over the entire dataset.

    **Raises**:	`AttributeError` – `privileged_groups` or `unprivileged_groups` must be provided at initialization to condition on them.

26. **`false_omission_rate_difference()`**: Compute the difference in false omission rates (FOR) between unprivileged and privileged groups.

$$
FOR_{D = \text{unprivileged}} - FOR_{D = \text{privileged}}
$$

27. **`false_omission_rate_ratio()`**: Compute the ratio of false omission rates (FOR) between unprivileged and privileged groups.
$$
\frac{FOR_{D = \text{unprivileged}}}{FOR_{D = \text{privileged}}}
$$


28. **`false_positive_rate(privileged=None)`**: Compute the false positive rate (FPR), which is the ratio of false positives to the total number of actual negatives.
    - 𝐹𝑃𝑅=𝐹𝑃/𝑁

    **Parameters**:	`privileged` (bool, optional) – Boolean prescribing whether to condition this metric on the `privileged_groups`, if `True`, or the `unprivileged_groups`, if `False`. Defaults to None meaning this metric is computed over the entire dataset.

    **Raises**:	`AttributeError` – `privileged_groups` or `unprivileged_groups` must be provided at initialization to condition on them.
29. **`false_positive_rate_difference()`**: Compute the difference in false positive rates (FPR) between unprivileged and privileged groups.
$$
FPR_{D = \text{unprivileged}} - FPR_{D = \text{privileged}}
$$


30. **`false_positive_rate_ratio()`**: Compute the ratio of false positive rates (FPR) between unprivileged and privileged groups.
$$
\frac{FPR_{D = \text{unprivileged}}}{FPR_{D = \text{privileged}}}
$$

31. **`generalized_binary_confusion_matrix(privileged=None)`**: Compute the number of generalized true/false positives/negatives, optionally conditioned on protected attributes. Generalized counts are based on scores and not on the hard predictions.

    **Parameters**:	`privileged` (*bool, optional*) – Boolean prescribing whether to condition this metric on the `privileged_groups`, if `True`, or the `unprivileged_groups`, if `False`. Defaults to `None` meaning this metric is computed over the entire dataset.
  
    **Returns**:	`dict` – Number of generalized true positives, generalized false positives, generalized true negatives, generalized false negatives (optionally conditioned).

32. **`generalized_entropy_index(alpha=2)`**: Generalized entropy index is proposed as a unified individual and group fairness measure With the formulas mentioned below.

      **Parameters**:	alpha (int) – Parameter that regulates the weight given to distances between values at different parts of the distribution.


$$
b_i = \hat{y}_i - y_i + 1
$$

$$
\mathcal{E}(\alpha) = \begin{cases}
\frac{1}{n \alpha (\alpha-1)}\sum_{i=1}^n\left[\left(\frac{b_i}{\mu}\right)^\alpha - 1\right],& \alpha \ne 0, 1,\\
\frac{1}{n}\sum_{i=1}^n\frac{b_{i}}{\mu}\ln\frac{b_{i}}{\mu},& \alpha=1,\\
-\frac{1}{n}\sum_{i=1}^n\ln\frac{b_{i}}{\mu},& \alpha=0.
\end{cases}
$$



33. **`generalized_false_negative_rate(privileged=None)`**: Compute the generalized false negative rate, which is the ratio of generalized false negatives to the total number of actual positives, optionally conditioned on protected attributes.

    - 𝐺𝐹𝑁𝑅=𝐺𝐹𝑁/𝑃
 

    **Parameters**:	`privileged` (*bool, optional*) – Boolean prescribing whether to condition this metric on the `privileged_groups`, if `True`, or the `unprivileged_groups`, if `False`. Defaults to None meaning this metric is computed over the entire dataset.

    **Raises**:	`AttributeError` – privileged_groups or unprivileged_groups must be provided at initialization to condition on them.


34. **`generalized_false_positive_rate(privileged=None)`**: Compute the generalized false positive rate, which is the ratio of generalized false positives to the total number of actual negatives, optionally conditioned on protected attributes.
    - 𝐺𝐹𝑃𝑅=𝐺𝐹𝑃/𝑁

    **Parameters**:	`privileged` (*bool, optional*) – Boolean prescribing whether to condition this metric on the `privileged_groups`, if `True`, or the `unprivileged_groups`, if `False`. Defaults to None meaning this metric is computed over the entire dataset.

    **Raises**:	`AttributeError` – privileged_groups or unprivileged_groups must be provided at initialization to condition on them.

35. **`generalized_true_negative_rate(privileged=None)`**: Compute the generalized true negative rate, which is the ratio of generalized true negatives to the total number of actual negatives, optionally conditioned on protected attributes.
      - 𝐺𝑇𝑁𝑅=𝐺𝑇𝑁/𝑁
    
    **Parameters**:	`privileged` (*bool, optional*) – Boolean prescribing whether to condition this metric on the `privileged_groups`, if `True`, or the `unprivileged_groups`, if `False`. Defaults to None meaning this metric is computed over the entire dataset.

    **Raises**:	`AttributeError` – privileged_groups or unprivileged_groups must be provided at initialization to condition on them.

36. **`generalized_true_positive_rate(privileged=None)`**: Compute the generalized true positive rate, which is the ratio of generalized true positives to the total number of actual positives, optionally conditioned on protected attributes.
      - 𝐺𝑇𝑃𝑅=𝐺𝑇𝑃/𝑃


    **Parameters**:	`privileged` (*bool, optional*) – Boolean prescribing whether to condition this metric on the `privileged_groups`, if `True`, or the `unprivileged_groups`, if `False`. Defaults to None meaning this metric is computed over the entire dataset.

    **Raises**:	`AttributeError` – privileged_groups or unprivileged_groups must be provided at initialization to condition on them.

37. **`negative_predictive_value(privileged=None)`**: Compute the negative predictive value (NPV), which is the ratio of true negatives to the total number of predicted negatives.
    - 𝑁𝑃𝑉=𝑇𝑁/(𝑇𝑁+𝐹𝑁)

    **Parameters**:	`privileged` (*bool, optional*) – Boolean prescribing whether to condition this metric on the `privileged_groups`, if `True`, or the `unprivileged_groups`, if `False`. Defaults to None meaning this metric is computed over the entire dataset.

    **Raises**:	`AttributeError` – privileged_groups or unprivileged_groups must be provided at initialization to condition on them.

38. **`num_false_negatives(privileged=None)`**: Compute the number of false negatives, optionally conditioned on protected attributes.

    **Parameters**:	`privileged` (*bool, optional*) – Boolean prescribing whether to condition this metric on the `privileged_groups`, if `True`, or the `unprivileged_groups`, if `False`. Defaults to None meaning this metric is computed over the entire dataset.

    **Raises**:	`AttributeError` – privileged_groups or unprivileged_groups must be provided at initialization to condition on them.

$$
FN = \sum_{i=1}^n \mathbb{1}[y_i = \text{favorable}]\mathbb{1}[\hat{y}_i = \text{unfavorable}]
$$


39. **`num_false_positives(privileged=None)`**: Compute the number of false positives, optionally conditioned on protected attributes.

    **Parameters**:	`privileged` (*bool, optional*) – Boolean prescribing whether to condition this metric on the `privileged_groups`, if `True`, or the `unprivileged_groups`, if `False`. Defaults to None meaning this metric is computed over the entire dataset.

    **Raises**:	`AttributeError` – privileged_groups or unprivileged_groups must be provided at initialization to condition on them.
$$
FP = \sum_{i=1}^n \mathbb{1}[y_i = \text{unfavorable}]\mathbb{1}[\hat{y}_i = \text{favorable}]
$$


40. **`num_generalized_false_negatives(privileged=None)`**: Return the generalized number of false negatives, 𝐺𝐹𝑁, the weighted sum of 1 - predicted scores where true labels are ‘favorable’, optionally conditioned on protected attributes.

    **Parameters**:	`privileged` (*bool, optional*) – Boolean prescribing whether to condition this metric on the `privileged_groups`, if `True`, or the `unprivileged_groups`, if `False`. Defaults to None meaning this metric is computed over the entire dataset.

    **Raises**:	`AttributeError` – privileged_groups or unprivileged_groups must be provided at initialization to condition on them.

41. **`num_generalized_false_positives(privileged=None)`**: Return the generalized number of false positives, 𝐺𝐹𝑃, the weighted sum of predicted scores where true labels are ‘unfavorable’, optionally conditioned on protected attributes.

    **Parameters**:	`privileged` (*bool, optional*) – Boolean prescribing whether to condition this metric on the `privileged_groups`, if `True`, or the `unprivileged_groups`, if `False`. Defaults to None meaning this metric is computed over the entire dataset.

    **Raises**:	`AttributeError` – privileged_groups or unprivileged_groups must be provided at initialization to condition on them.

42. **`num_generalized_true_negatives(privileged=None)`**: Return the generalized number of true negatives, 𝐺𝑇𝑁, the weighted sum of 1 - predicted scores where true labels are ‘unfavorable’, optionally conditioned on protected attributes.

    **Parameters**:	`privileged` (*bool, optional*) – Boolean prescribing whether to condition this metric on the `privileged_groups`, if `True`, or the `unprivileged_groups`, if `False`. Defaults to None meaning this metric is computed over the entire dataset.

    **Raises**:	`AttributeError` – privileged_groups or unprivileged_groups must be provided at initialization to condition on them.

43. **`num_generalized_true_positives(privileged=None)`**: CReturn the generalized number of true positives, 𝐺𝑇𝑃, the weighted sum of predicted scores where true labels are ‘favorable’, optionally conditioned on protected attributes.

    **Parameters**:	`privileged` (*bool, optional*) – Boolean prescribing whether to condition this metric on the `privileged_groups`, if `True`, or the `unprivileged_groups`, if `False`. Defaults to None meaning this metric is computed over the entire dataset.

    **Raises**:	`AttributeError` – privileged_groups or unprivileged_groups must be provided at initialization to condition on them.

44. **`num_pred_negatives(privileged=None)`**: Compute the number of predicted negatives, optionally conditioned on protected attributes.

    **Parameters**:	`privileged` (*bool, optional*) – Boolean prescribing whether to condition this metric on the `privileged_groups`, if `True`, or the `unprivileged_groups`, if `False`. Defaults to None meaning this metric is computed over the entire dataset.

    **Raises**:	`AttributeError` – privileged_groups or unprivileged_groups must be provided at initialization to condition on them.
$$
\sum_{i=1}^n \mathbb{1}[\hat{y}_i = \text{unfavorable}]
$$


45. **`num_pred_positives(privileged=None)`**: Compute the number of predicted positives, optionally conditioned on protected attributes.

    **Parameters**:	`privileged` (*bool, optional*) – Boolean prescribing whether to condition this metric on the `privileged_groups`, if `True`, or the `unprivileged_groups`, if `False`. Defaults to None meaning this metric is computed over the entire dataset.

    **Raises**:	`AttributeError` – privileged_groups or unprivileged_groups must be provided at initialization to condition on them.

$$
\sum_{i=1}^n \mathbb{1}[\hat{y}_i = \text{favorable}]
$$

46. **`num_true_negatives(privileged=None)`**: Compute the number of true negatives, optionally conditioned on protected attributes.

    **Parameters**:	`privileged` (*bool, optional*) – Boolean prescribing whether to condition this metric on the `privileged_groups`, if `True`, or the `unprivileged_groups`, if `False`. Defaults to None meaning this metric is computed over the entire dataset.

    **Raises**:	`AttributeError` – privileged_groups or unprivileged_groups must be provided at initialization to condition on them.
$$
TN = \sum_{i=1}^n \mathbb{1}[y_i = \text{unfavorable}]\mathbb{1}[\hat{y}_i = \text{unfavorable}]
$$

47. **`num_true_positives(privileged=None)`**: Compute the number of true positives, optionally conditioned on protected attributes.

    **Parameters**:	`privileged` (*bool, optional*) – Boolean prescribing whether to condition this metric on the `privileged_groups`, if `True`, or the `unprivileged_groups`, if `False`. Defaults to None meaning this metric is computed over the entire dataset.

    **Raises**:	`AttributeError` – privileged_groups or unprivileged_groups must be provided at initialization to condition on them.
$$
TP = \sum_{i=1}^n \mathbb{1}[y_i = \text{favorable}]\mathbb{1}[\hat{y}_i = \text{favorable}]
$$

48. **`performance_measures(privileged=None)`**: Compute various performance measures on the dataset, optionally conditioned on protected attributes.

    **Parameters**:	`privileged` (*bool, optional*) – Boolean prescribing whether to condition this metric on the `privileged_groups`, if `True`, or the `unprivileged_groups`, if `False`. Defaults to None meaning this metric is computed over the entire dataset.

    **Raises**:	`AttributeError` – privileged_groups or unprivileged_groups must be provided at initialization to condition on them.

49. **`positive_predictive_value(privileged=None)`**: Compute the positive predictive value (PPV), also known as precision, which is the ratio of true positives to the total number of predicted positives.
    - 𝑃𝑃𝑉=𝑇𝑃/(𝑇𝑃+𝐹𝑃)

    **Parameters**:	`privileged` (*bool, optional*) – Boolean prescribing whether to condition this metric on the `privileged_groups`, if `True`, or the `unprivileged_groups`, if `False`. Defaults to None meaning this metric is computed over the entire dataset.

    **Raises**:	`AttributeError` – privileged_groups or unprivileged_groups must be provided at initialization to condition on them.

50. **`power(privileged=None)`**: Compute the power, which is the number of true positives, optionally conditioned on protected attributes. Alias of `num_true_positives()`.

    **Parameters**:	`privileged` (*bool, optional*) – Boolean prescribing whether to condition this metric on the `privileged_groups`, if `True`, or the `unprivileged_groups`, if `False`. Defaults to None meaning this metric is computed over the entire dataset.

    **Raises**:	`AttributeError` – privileged_groups or unprivileged_groups must be provided at initialization to condition on them.

51. **`precision(privileged=None)`**: Compute the precision, which is the positive predictive value (PPV), optionally conditioned on protected attributes. Alias of `positive_predictive_value()`.

    **Parameters**:	`privileged` (*bool, optional*) – Boolean prescribing whether to condition this metric on the `privileged_groups`, if `True`, or the `unprivileged_groups`, if `False`. Defaults to None meaning this metric is computed over the entire dataset.

    **Raises**:	`AttributeError` – privileged_groups or unprivileged_groups must be provided at initialization to condition on them.

52. **`recall(privileged=None)`**: Compute the recall, which is the true positive rate (TPR), optionally conditioned on protected attributes. Alias of `true_positive_rate()`.

    **Parameters**:	`privileged` (*bool, optional*) – Boolean prescribing whether to condition this metric on the `privileged_groups`, if `True`, or the `unprivileged_groups`, if `False`. Defaults to None meaning this metric is computed over the entire dataset.

    **Raises**:	`AttributeError` – privileged_groups or unprivileged_groups must be provided at initialization to condition on them.

53. **`selection_rate(privileged=None)`**: Compute the selection rate, which is the probability of being classified as "favorable," optionally conditioned on protected attributes.

    **Parameters**:	`privileged` (*bool, optional*) – Boolean prescribing whether to condition this metric on the `privileged_groups`, if `True`, or the `unprivileged_groups`, if `False`. Defaults to None meaning this metric is computed over the entire dataset.

    **Raises**:	`AttributeError` – privileged_groups or unprivileged_groups must be provided at initialization to condition on them.
$$
Pr(\hat{Y} = \text{favorable})
$$

54. **`sensitivity(privileged=None)`**: Compute the sensitivity, which is the true positive rate (TPR), optionally conditioned on protected attributes. Alias of `true_positive_rate()`.

    **Parameters**:	`privileged` (*bool, optional*) – Boolean prescribing whether to condition this metric on the `privileged_groups`, if `True`, or the `unprivileged_groups`, if `False`. Defaults to None meaning this metric is computed over the entire dataset.

    **Raises**:	`AttributeError` – privileged_groups or unprivileged_groups must be provided at initialization to condition on them.

55. **`specificity(privileged=None)`**: Compute the specificity, which is the true negative rate (TNR), optionally conditioned on protected attributes. Alias of `true_negative_rate()`.

    **Parameters**:	`privileged` (*bool, optional*) – Boolean prescribing whether to condition this metric on the `privileged_groups`, if `True`, or the `unprivileged_groups`, if `False`. Defaults to None meaning this metric is computed over the entire dataset.

    **Raises**:	`AttributeError` – privileged_groups or unprivileged_groups must be provided at initialization to condition on them.

56. **`statistical_parity_difference()`**: Compute the statistical parity difference, which measures the difference in the probability of receiving a "favorable" classification between unprivileged and privileged groups.
$$
Pr(\hat{Y} = 1 | D = \text{unprivileged}) - Pr(\hat{Y} = 1 | D = \text{privileged})
$$

57. **`theil_index()`**: Compute the Theil index, which is a fairness measure related to the generalized entropy index. The Theil index is the `generalized_entropy_index()` with `𝛼=1`
.

58. **`true_negative_rate(privileged=None)`**: Compute the true negative rate (TNR), also known as specificity, which is the ratio of true negatives to the total number of actual negatives.
    - 𝑇𝑁𝑅=𝑇𝑁/𝑁

    **Parameters**:	`privileged` (*bool, optional*) – Boolean prescribing whether to condition this metric on the `privileged_groups`, if `True`, or the `unprivileged_groups`, if `False`. Defaults to None meaning this metric is computed over the entire dataset.

    **Raises**:	`AttributeError` – privileged_groups or unprivileged_groups must be provided at initialization to condition on them.

59. **`true_positive_rate(privileged=None)`**: Return the ratio of true positives to positive examples in the dataset, 𝑇𝑃𝑅=𝑇𝑃/𝑃, optionally conditioned on protected attributes.

    **Parameters**:	`privileged` (*bool, optional*) – Boolean prescribing whether to condition this metric on the `privileged_groups`, if `True`, or the `unprivileged_groups`, if `False`. Defaults to None meaning this metric is computed over the entire dataset.

    **Raises**:	`AttributeError` – privileged_groups or unprivileged_groups must be provided at initialization to condition on them.

60. **`true_positive_rate_difference()`**: Compute the TPRD

$$
TPR_{D = \text{unprivileged}} - TPR_{D = \text{privileged}}
$$

#### 4. SampleDistortionMetric
**Class**:`aif360.metrics.SampleDistortionMetric` (*(dataset, distorted_dataset, unprivileged_groups=None, privileged_groups=None)*)

**Description**:Class for computing metrics based on two StructuredDatasets.
**Initialization**:
```python
__init__(dataset, distorted_dataset, unprivileged_groups=None, privileged_groups=None)
```

#### Parameters
- `dataset` (*StructuredDataset*) – A StructuredDataset.
- `distorted_dataset` (*StructuredDataset*) – A StructuredDataset.
- `privileged_groups` (*list(dict)*) – Privileged groups. Format is a list of dicts where the keys are protected_attribute_names and the values are values in protected_attributes. Each dict element describes a single group. See examples for more details.
- `unprivileged_groups` (*list(dict)*) – Unprivileged groups in the same format as privileged_groups.

#### Methods

1. **`average()`**: Compute the average distortion metric over all instances in the dataset.
   
   **Parameters**: None
   
   **Returns**: *float* - The average distortion metric value.

2. **`average_euclidean_distance()`**: Compute the average Euclidean distance between the samples from the two datasets.
   
   **Parameters**: None
   
   **Returns**: *float* - The average Euclidean distance.

3. **`average_mahalanobis_distance()`**: Compute the average Mahalanobis distance between the samples from the two datasets.
   
   **Parameters**: None
   
   **Returns**: *float* - The average Mahalanobis distance.

4. **`average_manhattan_distance()`**: Compute the average Manhattan distance between the samples from the two datasets.
   
   **Parameters**: None
   
   **Returns**: *float* - The average Manhattan distance.

5. **`difference()`**: Compute the difference of the metric for unprivileged and privileged groups.
   
   **Parameters**: None
   
   **Returns**: *float* - The difference of the metric for unprivileged and privileged groups.

6. **`euclidean_distance`(*privileged=None, returned=False*)**: Compute the average Euclidean distance between the samples from the two datasets.
   
   **Parameters**:
     - `privileged` (bool, optional): Boolean prescribing whether to condition this metric on `privileged groups`. Defaults to `None`, meaning this metric is computed over the entire dataset.
     - `returned` (bool, optional): Boolean indicating whether to return the value. Defaults to False.
  
    **Returns**: *float* - The average Euclidean distance.

7. **`mahalanobis_distance`(*privileged=None, returned=False*)**: Compute the average Mahalanobis distance between the samples from the two datasets.
   
   **Parameters**:
     - `privileged` (bool, optional): Boolean prescribing whether to condition this metric on privileged groups. Defaults to None, meaning this metric is computed over the entire dataset.
     - `returned` (bool, optional): Boolean indicating whether to return the value. Defaults to False.
   
    **Returns**: *float* - The average Mahalanobis distance.

8. **`manhattan_distance(privileged=None, returned=False)`**: Compute the average Manhattan distance between the samples from the two datasets.
   
   **Parameters**:
     - `privileged` (*bool, optional*): Boolean prescribing whether to condition this metric on privileged groups. Defaults to None, meaning this metric is computed over the entire dataset.
     - `returned` (bool, optional): Boolean indicating whether to return the value. Defaults to False.
   
    **Returns**: *float* - The average Manhattan distance.

9. **`maximum()`**: Compute the maximum distortion metric value.
   
   **Parameters**: None
   
   **Returns**: *float* - The maximum distortion metric value.

10. **`maximum_euclidean_distance()`**: Compute the maximum Euclidean distance between the samples from the two datasets.
    
    **Parameters**: None
    
    **Returns**: *float* - The maximum Euclidean distance.

11. **`maximum_mahalanobis_distance()`**: Compute the maximum Mahalanobis distance between the samples from the two datasets.
    
    **Parameters**: None
    
    **Returns**: *float* - The maximum Mahalanobis distance.

12. **`maximum_manhattan_distance()`**: Compute the maximum Manhattan distance between the samples from the two datasets.
    
    **Parameters**: None
    
    **Returns**: *float* - The maximum Manhattan distance.

13. **`mean_euclidean_distance_difference(privileged=None)`**: Compute the difference of the averages of Euclidean distances.
    
    **Parameters**:
      - `privileged` (*bool, optional*): Boolean prescribing whether to condition this metric on privileged groups. Defaults to None, meaning this metric is computed over the entire dataset.
    
    **Returns**: *float* - The difference of the averages of Euclidean distances.

14. **`mean_euclidean_distance_ratio(privileged=None)`**: Compute the ratio of the averages of Euclidean distances.
    
    **Parameters**:
      - `privileged` (*bool, optional*): Boolean prescribing whether to condition this metric on privileged groups. Defaults to None, meaning this metric is computed over the entire dataset.
    
    **Returns**: *float* - The ratio of the averages of Euclidean distances.

15. **`mean_mahalanobis_distance_difference(privileged=None)`**: Compute the difference of the averages of Mahalanobis distances.
    
    **Parameters**:
      - `privileged` (*bool, optional*): Boolean prescribing whether to condition this metric on privileged groups. Defaults to None, meaning this metric is computed over the entire dataset.
    
    **Returns**: *float* - The difference of the averages of Mahalanobis distances.

16. **`mean_mahalanobis_distance_ratio(privileged=None)`**: Compute the ratio of the averages of Mahalanobis distances.
    
    **Parameters**:
      - `privileged` (*bool, optional*): Boolean prescribing whether to condition this metric on privileged groups. Defaults to None, meaning this metric is computed over the entire dataset.
    
    **Returns**: *float* - The ratio of the averages of Mahalanobis distances.

17. **`mean_manhattan_distance_difference(privileged=None)`**: Compute the difference of the averages of Manhattan distances.
    
    **Parameters**:
      - `privileged` (*bool, optional*): Boolean prescribing whether to condition this metric on privileged groups. Defaults to None, meaning this metric is computed over the entire dataset.
    
    **Returns**: *float* - The difference of the averages of Manhattan distances.

18. **`mean_manhattan_distance_ratio(privileged=None)`**: Compute the ratio of the averages of Manhattan distances.
    
    **Parameters**:
      - `privileged` (bool, optional): Boolean prescribing whether to condition this metric on privileged groups. Defaults to None, meaning this metric is computed over the entire dataset.
    
    **Returns**: *float* - The ratio of the averages of Manhattan distances.

19. **`num_instances()`**: Compute the number of instances in the dataset conditioned on protected attributes if necessary.
    
    **Parameters**: None
    
    **Returns**: *int* - The number of instances in the dataset.

20. **`ratio()`**: Compute the ratio of the distortion metric for unprivileged and privileged groups.
    
    **Parameters**: None
    
    **Returns**: *float* - The ratio of the distortion metric for unprivileged and privileged groups.

21. **`total()`**: Compute the total distortion metric value.
    
    **Parameters**: None
    
    **Returns**: *float* - The total distortion metric value.

22. **`total_euclidean_distance()`**: Compute the total Euclidean distance between the samples from the two datasets.
    
    **Parameters**: None
    
    **Returns**: *float* - The total Euclidean distance.

23. **`total_mahalanobis_distance()`**: Compute the total Mahalanobis distance between the samples from the two datasets.
    
    **Parameters**: None
    
    **Returns**: *float* - The total Mahalanobis distance.

24. **`total_manhattan_distance()`**: Compute the total Manhattan distance between the samples from the two datasets.
    
    **Parameters**: None
    
    **Returns**: *float* - The total Manhattan distance.

These methods provide various ways to compute distortion metrics, distances, and related statistics between two datasets, and some of them also allow for conditioning on privileged groups if necessary. The specific metric or distance computed depends on the method called.

#### 5. MDSSClassificationMetric
**Class**:`aif360.metrics.MDSSClassificationMetric`(_dataset: aif360.datasets.binary_label_dataset.BinaryLabelDataset, classified_dataset: aif360.datasets.binary_label_dataset.BinaryLabelDataset, scoring: Union[str, aif360.detectors.mdss.ScoringFunctions.ScoringFunction.ScoringFunction] = 'Bernoulli', unprivileged_groups: dict = None, privileged_groups: dict = None, **kwargs_)

**Description**:
- Bias subset scanning is proposed as a technique to identify bias in predictive models using subset scanning.
- This class is a wrapper for the bias scan scoring and scanning methods that uses the ClassificationMetric abstraction.

**Initialization**:
```python
__init__(dataset: aif360.datasets.binary_label_dataset.BinaryLabelDataset, classified_dataset: aif360.datasets.binary_label_dataset.BinaryLabelDataset, scoring: Union[str, aif360.detectors.mdss.ScoringFunctions.ScoringFunction.ScoringFunction] = 'Bernoulli', unprivileged_groups: dict = None, privileged_groups: dict = None, **kwargs)
```

**Parameters**:	
- `dataset` (*BinaryLabelDataset*) – Dataset containing ground-truth labels.
- `classified_dataset` (*BinaryLabelDataset*) – Dataset containing predictions.
- `scoring` (*str or ScoringFunction*) – One of ‘Bernoulli’ (parametric), or ‘BerkJones’ (non-parametric) or subclass of `aif360.metrics.mdss.ScoringFunctions.ScoringFunction`. Defaults to Bernoulli.
- `privileged_groups` (*list(dict)*) – Privileged groups. Format is a list of `dicts` where the keys are `protected_attribute_names` and the values are values in `protected_attributes`. Each `dict` element describes a single group. See examples for more details.
- `unprivileged_groups` (list(dict)) – Unprivileged groups in the same format as privileged_groups.

**Methods**:

1. **`accuracy()`**: Compute the accuracy metric, defined as 𝐴𝐶𝐶=(𝑇𝑃+𝑇𝑁)/(𝑃+𝑁).
   - **Parameters**: None
   - **Returns**: *float* - The accuracy metric value.

2. **`average_abs_odds_difference()`**: Compute the average of the absolute difference in false positive rate (FPR) and true positive rate (TPR) for unprivileged and privileged groups.
   - **Parameters**: None
   - **Returns**: *float* - The average absolute odds difference.

3. **`average_odds_difference()`**: Compute the average of the difference in FPR and TPR for unprivileged and privileged groups.
   - **Parameters**: None
   - **Returns**: *float* - The average odds difference.

4. **`average_predictive_value_difference()`**: Compute the average of the difference in positive predictive value (PPV) and false omission rate (FOR) for unprivileged and privileged groups.
   - **Parameters**: None
   - **Returns**: *float* - The average predictive value difference.

5. **`base_rate()`**: Compute the base rate, 𝑃𝑟(𝑌=1)=𝑃/(𝑃+𝑁), optionally conditioned on protected attributes.
   - **Parameters**: None
   - **Returns**: *float* - The base rate.

6. **`between_all_groups_coefficient_of_variation()`**: The between-group coefficient of variation is the square root of two times the `between_all_groups_generalized_entropy_index()` with 𝛼=2.
   - **Parameters**: None
   - **Returns**: *float* - The coefficient of variation between all groups.

7. **`between_all_groups_generalized_entropy_index()`**: Between-group generalized entropy index that uses all combinations of groups based on self.dataset.protected_attributes.
   - **Parameters**: None
   - **Returns**: *float* - The between-group generalized entropy index.

8. **`between_all_groups_theil_index()`**: The between-group Theil index is the `between_all_groups_generalized_entropy_index()` with 𝛼=1.
   - **Parameters**: None
   - **Returns**: *float* - The between-group Theil index.

9. **`between_group_coefficient_of_variation()`**: The between-group coefficient of variation is the square root of two times the `between_group_generalized_entropy_index()` with 𝛼=2.
   - **Parameters**: None
   - **Returns**: *float* - The coefficient of variation between group.

10. **`between_group_generalized_entropy_index()`**: Between-group generalized entropy index that uses self.privileged_groups and self.unprivileged_groups as the only two groups.
    - **Parameters**: None
    - **Returns**: *float* - The between-group generalized entropy index.

11. **`between_group_theil_index()`**: The between-group Theil index is the `between_group_generalized_entropy_index()` with 𝛼=1.
    - **Parameters**: None
    - **Returns**: *float* - The between-group Theil index.

12. **`bias_scan(privileged=True, num_iters=10, penalty=1e-17)`**: DEPRECATED: Change to new interface - `aif360.detectors.mdss_detector.bias_scan` by version 0.5.0.
    - **Parameters**:
      - `privileged` (*bool*): Flag for group to scan for - privileged group (True) or unprivileged group (False). This abstracts the need to explicitly specify the direction of bias to scan for, which depends on what the favorable label is.
      - `num_iters` (*int*): Number of iterations (random restarts).
      - `penalty` (*float*): Penalty term. Should be positive. The penalty term, like any regularization parameter, may need to be tuned for one's use case. The higher the penalty, the less complex (number of features and feature values) the highest scoring subset that gets returned is.
    - **Returns**: *tuple* - The highest scoring subset and the score.

13. **`binary_confusion_matrix()`**: Compute the number of true/false positives/negatives, optionally conditioned on protected attributes.
    - **Parameters**: None
    - **Returns**: *dict* - A dictionary containing the counts of true positives, true negatives, false positives, and false negatives.

14. **`coefficient_of_variation()`**: The coefficient of variation is the square root of two times the generalized entropy index() with 𝛼=2.
    - **Parameters**: None
    - **Returns**: *float* - The coefficient of variation.

15. **`consistency()`**: Individual fairness metric that measures how similar the labels are for similar instances.
    - **Parameters**: None
    - **Returns**: *float* - The consistency metric value.

16. **`difference()`**: Compute the difference of the metric for unprivileged and privileged groups.
    - **Parameters**: None
    - **Returns**: *float* - The difference of the metric for unprivileged and privileged groups.

17. **`differential_fairness_bias_amplification()`**: Bias amplification is the difference in smoothed EDF between the classifier and the original dataset.
    - **Parameters**: None
    - **Returns**: *float* - The bias amplification value.

18. **`disparate_impact()`**: Alias of `disparate_impact()`.
    - **Parameters**: None
    - **Returns**: *float* - The disparate impact value.

19. **`equal_opportunity_difference()`**: Alias of `true_positive_rate_difference()`.
    - **Parameters**: None
    - **Returns**: *float* - The equal opportunity difference.

20. **`error_rate()`**: Compute the error rate, 𝐸𝑅𝑅=(𝐹𝑃+𝐹𝑁)/(𝑃+𝑁).
    - **Parameters**: None
    - **Returns**: *float* - The error rate value.

21. **`error_rate_difference()`**: Difference in error rates for unprivileged and privileged groups, 𝐸𝑅𝑅𝐷=unprivileged−𝐸𝑅𝑅𝐷=privileged.
    - **Parameters**: None
    - **Returns**: *float* - The error rate difference.

22. **`error_rate_ratio()`**: Ratio of error rates for unprivileged and privileged groups, 𝐸𝑅𝑅𝐷=unprivileged/𝐸𝑅𝑅𝐷=privileged.
    - **Parameters**: None
    - **Returns**: *float* - The error rate ratio.

23. **`false_discovery_rate()`**: Compute the false discovery rate, 𝐹𝐷𝑅=𝐹𝑃/(𝑇𝑃+𝐹𝑃).
    - **Parameters**: None
    - **Returns**: *float* - The false discovery rate.

24. **`false_discovery_rate_difference()`**: 𝐹𝐷𝑅𝐷=unprivileged−𝐹𝐷𝑅𝐷=privileged.
    - **Parameters**: None
    - **Returns**: *float* - The false discovery rate difference.

25. **`false_discovery_rate_ratio()`**: 𝐹𝐷𝑅𝐷=unprivileged/𝐹𝐷𝑅𝐷=privileged.
    - **Parameters**: None
    - **Returns**: *float* - The false discovery rate ratio.

26. **`false_negative_rate()`**: Compute the false negative rate, 𝐹𝑁𝑅=𝐹𝑁/𝑃.
    - **Parameters**: None
    - **Returns**: *float* - The false negative rate.

27. **`false_negative_rate_difference()`**: 𝐹𝑁𝑅𝐷=unprivileged−𝐹𝑁𝑅𝐷=privileged.
    - **Parameters**: None
    - **Returns**: *float* - The false negative rate difference.

28. **`false_negative_rate_ratio()`**: 𝐹𝑁𝑅𝐷=unprivileged/𝐹𝑁𝑅𝐷=privileged.
    - **Parameters**: None
    - **Returns**: *float* - The false negative rate ratio.

29. **`false_omission_rate()`**: Compute the false omission rate, 𝐹𝑂𝑅=𝐹𝑁/(𝑇𝑁+𝐹𝑁).
    - **Parameters**: None
    - **Returns**: *float* - The false omission rate.

30. **`false_omission_rate_difference()`**: 𝐹𝑂𝑅𝐷=unprivileged−𝐹𝑂𝑅𝐷=privileged.
    - **Parameters**: None
    - **Returns**: *float* - The false omission rate difference.

31. **`false_omission_rate_ratio()`**: 𝐹𝑂𝑅𝐷=unprivileged/𝐹𝑂𝑅𝐷=privileged.
    - **Parameters**: None
    - **Returns**: *float* - The false omission rate ratio.

32. **`false_positive_rate()`**: Compute the false positive rate, 𝐹𝑃𝑅=𝐹𝑃/𝑁.
    - **Parameters**: None
    - **Returns**: *float* - The false positive rate.

33. **`false_positive_rate_difference()`**: 𝐹𝑃𝑅𝐷=unprivileged−𝐹𝑃𝑅𝐷=privileged.
    - **Parameters**: None
    - **Returns**: *float* - The false positive rate difference.

34. **`false_positive_rate_ratio()`**: 𝐹𝑃𝑅𝐷=unprivileged/𝐹𝑃𝑅𝐷=privileged.
    - **Parameters**: None
    - **Returns**: *float* - The false positive rate ratio.

35. **`generalized_binary_confusion_matrix()`**: Compute the number of generalized true/false positives/negatives, optionally conditioned on protected attributes.
    - **Parameters**: None
    - **Returns**: *dict* - A dictionary containing the counts of generalized true positives, generalized true negatives, generalized false positives, and generalized false negatives.

36. **`generalized_entropy_index()`**: Generalized entropy index is proposed as a unified individual and group fairness measure.
    - **Parameters**: None
    - **Returns**: *float* - The generalized entropy index.

37. **`generalized_false_negative_rate()`**: 𝐺𝐹𝑁𝑅=𝐺𝐹𝑁/𝑃.
    - **Parameters**: None
    - **Returns**: *float* - The generalized false negative rate.

38. **`generalized_false_positive_rate()`**: 𝐺𝐹𝑃𝑅=𝐺𝐹𝑃/𝑁.
    - **Parameters**: None
    - **Returns**: *float* - The generalized false positive rate.

39. **`generalized_true_negative_rate()`**: 𝐺𝑇𝑁𝑅=𝐺𝑇𝑁/𝑁.
    - **Parameters**: None
    - **Returns**: *float* - The generalized true negative rate.

40. **`generalized_true_positive_rate()`**: Return the ratio of generalized true positives to positive examples in the dataset, 𝐺𝑇𝑃𝑅=𝐺𝑇𝑃/𝑃, optionally conditioned on protected attributes.
    - **Parameters**: None
    - **Returns**: *float* - The generalized true positive rate.

41. **`mean_difference()`**: Alias of `statistical_parity_difference()`.
    - **Parameters**: None
    - **Returns**: *float* - The mean difference.

42. **`negative_predictive_value()`**: 𝑁𝑃𝑉=𝑇𝑁/(𝑇𝑁+𝐹𝑁).
    - **Parameters**: None
    - **Returns**: *float* - The negative predictive value.

43. **`num_false_negatives()`**: 𝐹𝑁=∑𝑛𝑖=1𝟙[𝑦𝑖=favorable]𝟙[𝑦̂ 𝑖=unfavorable].
    - **Parameters**: None
    - **Returns**: *int* - The number of false negatives.

44. **`num_false_positives()`**: 𝐹𝑃=∑𝑛𝑖=1𝟙[𝑦𝑖=unfavorable]𝟙[𝑦̂ 𝑖=favorable].
    - **Parameters**: None
    - **Returns**: *int* - The number of false positives.

45. **`num_generalized_false_negatives()`**: Return the generalized number of false negatives, 𝐺𝐹𝑁, the weighted sum of 1 - predicted scores where true labels are ‘favorable’, optionally conditioned on protected attributes.
    - **Parameters**: None
    - **Returns**: *float* - The generalized number of false negatives.

46. **`num_generalized_false_positives()`**: Return the generalized number of false positives, 𝐺𝐹𝑃, the weighted sum of predicted scores where true labels are ‘unfavorable’, optionally conditioned on protected attributes.
    - **Parameters**: None
    - **Returns**: *float* - The generalized number of false positives.

47. **`num_generalized_true_negatives()`**: Return the generalized number of true negatives, 𝐺𝑇𝑁, the weighted sum of 1 - predicted scores where true labels are ‘unfavorable’, optionally conditioned on protected attributes.
    - **Parameters**: None
    - **Returns**: *float* - The generalized number of true negatives.

48. **`num_generalized_true_positives()`**: Return the generalized number of true positives, 𝐺𝑇𝑃, the weighted sum of predicted scores where true labels are ‘favorable’, optionally conditioned on protected attributes.
    - **Parameters**: None
    - **Returns**: *float* - The generalized number of true positives.

49. **`num_instances()`**: Compute the number of instances, 𝑛, in the dataset conditioned on protected attributes if necessary.
    - **Parameters**: None
    - **Returns**: *int* - The number of instances.

50. **`num_negatives()`**: Compute the number of negatives, 𝑁=∑𝑛𝑖=1𝟙[𝑦𝑖=0], optionally conditioned on protected attributes.
    - **Parameters**: None
    - **Returns**: *int* - The number of negatives.

51. **`num_positives()`**: Compute the number of positives, 𝑃=∑𝑛𝑖=1𝟙[𝑦𝑖=1], optionally conditioned on protected attributes.
    - **Parameters**: None
    - **Returns**: *int* - The number of positives.

52. **`num_pred_negatives()`**: ∑𝑛𝑖=1𝟙[𝑦̂ 𝑖=unfavorable].
    - **Parameters**: None
    - **Returns**: *int* - The number of predicted negatives.

53. **`num_pred_positives()`**: ∑𝑛𝑖=1𝟙[𝑦̂ 𝑖=favorable].
    - **Parameters**: None
    - **Returns**: *int* - The number of predicted positives.

54. **`num_true_negatives()`**: 𝑇𝑁=∑𝑛𝑖=1𝟙[𝑦𝑖=unfavorable]𝟙[𝑦̂ 𝑖=unfavorable].
    - **Parameters**: None
    - **Returns**: *int* - The number of true negatives.

55. **`num_true_positives()`**: Return the number of instances in the dataset where both the predicted and true labels are ‘favorable’, 𝑇𝑃=∑𝑛𝑖=1𝟙[𝑦𝑖=favorable]𝟙[𝑦̂ 𝑖=favorable], optionally conditioned on protected attributes.
    - **Parameters**: None
    - **Returns**: *int* - The number of true positives.

56. **`performance_measures()`**: Compute various performance measures on the dataset, optionally conditioned on protected attributes.
    - **Parameters**: None
    - **Returns**: *dict* - A dictionary containing various performance measures.

57. **`positive_predictive_value()`**: 𝑃𝑃𝑉=𝑇𝑃/(𝑇𝑃+𝐹𝑃).
    - **Parameters**: None
    - **Returns**: *float* - The positive predictive value.

58. **`power()`**: Alias of `num_true_positives()`.
    - **Parameters**: None
    - **Returns**: *int* - The power.

59. **`precision()`**: Alias of `positive_predictive_value()`.
    - **Parameters**: None
    - **Returns**: *float* - The precision.

60. **`ratio()`**: Compute the ratio of the metric for unprivileged and privileged groups.
    - **Parameters**: None
    - **Returns**: *float* - The ratio of the metric for unprivileged and privileged groups.

61. **`recall()`**: Alias of `true_positive_rate()`.
    - **Parameters**: None
    - **Returns**: *float* - The recall.

62. **`rich_subgroup()`**: Audit dataset with respect to rich subgroups defined by linear thresholds of sensitive attributes.
    - **Parameters**: None
    - **Returns**: *aif360.datasets.binary_label_dataset.BinaryLabelDataset* - The audit dataset.

63. **`score_groups(privileged=True, penalty=1e-17)`**: Compute the bias score for a prespecified group of records.
    - **Parameters**: `privileged` (*bool*) – Flag for which direction to scan: privileged (True) implies negative (observed worse than predicted outcomes) while unprivileged (False) implies positive (observed better than predicted outcomes).
    - **Returns**: *float* - The bias score for the given group. The higher the score, the evidence for bias.

64. **`bias_scan`**(*privileged=True, num_iters=10, penalty=1e-17*)


    DEPRECATED: Change to new interface - aif360.detectors.mdss_detector.bias_scan by version 0.5.0.
scan to find the highest scoring subset of records

    **Parameters**:	privileged – flag for group to scan for - privileged group (True) or unprivileged group (False).
    - This abstract the need to explicitly specify the direction of bias to scan for which depends on what the favourable label is. :param num_iters: number of iterations (random restarts) :param penalty: penalty term. Should be positive. The penalty term as with any regularization parameter may need to be tuned for ones use case. The higher the penalty, the less complex (number of features and feature values) the highest scoring subset that gets returned is.

    **Returns**:	the highest scoring subset and the score
### 2. aif360.metrics.utils

- aif360.metrics.utils.compute_boolean_conditioning_vector
- aif360.metrics.utils.compute_num_instances
- aif360.metrics.utils.compute_num_pos_neg
- aif360.metrics.utils.compute_num_TF_PN
- aif360.metrics.utils.compute_num_gen_TF_PN
- aif360.metrics.utils.compute_distance

#### 1. aif360.metrics.utils.compute_boolean_conditioning_vector


**Class**:`aif360.metrics.utils.compute_boolean_conditioning_vector`

**Description**: Compute the boolean conditioning vector.

**Parameters**:
```python
aif360.metrics.utils.compute_boolean_conditioning_vector(X, feature_names, condition=None)
```
- `X` (*numpy.ndarray*) – Dataset features.
- `feature_names` (*list*) – Names of the features.
- `condition` (*list(dict)*) – Specifies the subset of instances we want to use. Format is a list of dicts where the keys are feature_names and the values are values in X. Elements in the list are clauses joined with OR operators while key-value pairs in each dict are joined with AND operators. See examples for more details. If None, the condition specifies the entire set of instances, X.

**Returns**:

- `numpy.ndarray(bool)` – Boolean conditioning vector. Shape is [n] where n is X.shape[0]. Values are True if the corresponding row satisfies the condition and False otherwise.

**Examples**:

```python
>>> condition = [{'sex': 1, 'age': 1}, {'sex': 0}]
```

> This corresponds to (sex == 1 AND age == 1) OR (sex == 0).


#### 2. aif360.metrics.utils.compute_num_instances

**Class**:`aif360.metrics.utils.compute_num_instances`
**Description**: Compute the number of instances, 𝑛, conditioned on the protected attribute(s).

**Parameters**:	`aif360.metrics.utils.compute_num_instances`(*X, w, feature_names, condition=None*)

- `X` (*numpy.ndarray*) – Dataset features.
- `w` (*numpy.ndarray*) – Instance weight vector.
- `feature_names` (*list*) – Names of the features.
- `condition` (*list(dict)*) – Same format as compute_boolean_conditioning_vector().

**Returns**:	
- `int` – Number of instances (optionally conditioned).

#### 3. aif360.metrics.utils.compute_num_pos_neg

**Class**:`aif360.metrics.utils.compute_num_pos_neg`

**Description**:Compute the number of positives, 𝑃, or negatives, 𝑁, optionally conditioned on protected attributes.

**Parameters**:	
`aif360.metrics.utils.compute_num_pos_neg`(*X, y, w, feature_names, label, condition=None*)

- `X` (*numpy.ndarray*) – Dataset features.
- `y` (*numpy.ndarray*) – Label vector.
- `w` (*numpy.ndarray*) – Instance weight vector.
- `feature_names` (*list*) – Names of the features.
- `label` (*float*) – Value of label (unfavorable/positive or unfavorable/negative).
- `condition` (*list(dict)*) – Same format as compute_boolean_conditioning_vector().

**Returns**:	
- `int` – Number of positives/negatives (optionally conditioned)

#### 4. aif360.metrics.utils.compute_num_TF_PN

**Class**:`aif360.metrics.utils.compute_num_TF_PN`

**Description**:Compute the number of true/false positives/negatives optionally conditioned on protected attributes.

**Parameters**:	
`aif360.metrics.utils.compute_num_TF_PN`(*X, y_true, y_pred, w, feature_names, favorable_label, unfavorable_label, condition=None*)

- `X` (*numpy.ndarray*) – Dataset features.
- `y_true` (*numpy.ndarray*) – True label vector.
- `y_pred` (*numpy.ndarray*) – Predicted label vector.
- `w` (*numpy.ndarray*) – Instance weight vector - the true and predicted datasets are supposed to have same instance level weights.
- `feature_names` (*list*) – names of the features.
- `favorable_label` (*float*) – Value of favorable/positive label.
- `unfavorable_label` (*float*) – Value of unfavorable/negative label.
- `condition` (*list(dict)*) – Same format as `compute_boolean_conditioning_vector()`.

**Returns**:	
- Number of positives/negatives (optionally conditioned).


#### 5. aif360.metrics.utils.compute_num_gen_TF_PN

**Class**:`aif360.metrics.utils.compute_num_gen_TF_PN`

**Description**:Compute the number of generalized true/false positives/negatives optionally conditioned on protected attributes. Generalized counts are based on scores and not on the hard predictions.

**Parameters**:	
`aif360.metrics.utils.compute_num_gen_TF_PN`(*X, y_true, y_score, w, feature_names, favorable_label, unfavorable_label, condition=None*)

- `X` (_numpy.ndarray_) – Dataset features.
- `y_true` (_numpy.ndarray_) – True label vector.
- `y_score` (_numpy.ndarray_) – Predicted score vector. Values range from 0 to 1. 0 implies prediction for unfavorable label and 1 implies prediction for favorable label.
- `w` (_numpy.ndarray_) – Instance weight vector - the true and predicted datasets are supposed to have same instance level weights.
- `feature_names` (_list_) – names of the features.
- `favorable_label` (_float_) – Value of favorable/positive label.
- `unfavorable_label` (_float_) – Value of unfavorable/negative label.
- `condition` (_list(dict)_) – Same format as compute_boolean_conditioning_vector().

**Returns**:	
- Number of positives/negatives (optionally conditioned).

#### 6.aif360.metrics.utils.compute_distance

**Class**:`aif360.metrics.utils.compute_distance`

**Description**:Compute the distance element-wise for two sets of vectors.

**Parameters**:	
`aif360.metrics.utils.compute_distance`(_X_orig, X_distort, X_prot, feature_names, dist_fun, condition=None_)

- `X_orig` (_numpy.ndarray_) – Original features.
- `X_distort` (_numpy.ndarray_) – Distorted features. Shape must match X_orig.
- `X_prot` (_numpy.ndarray_) – Protected attributes (used to compute condition). Should be same for both original and distorted.
- `feature_names` (_list_) – Names of the protected features.
- `dist_fun` (_function_) – Function which returns the distance (float) between two 1-D arrays (e.g. scipy.spatial.distance.euclidean()).
- `condition` (_list(dict)_) – Same format as `compute_boolean_conditioning_vector()`.

**Returns**:	
- (numpy.ndarray(numpy.float64), numpy.ndarray(bool)) – * Element-wise distances (1-D). * Condition vector (1-D).
---
---

## Explainers
- explainers.MetricTextExplainer
- explainers.MetricJSONExplainer
#### 1. MetricsTextExplainer
**Class**: `aif360.explainers.MetricTextExplainer`(_metric_)

**Description**:
- The MetricTextExplainer class is designed to provide explanations for metric values using text descriptions. Metrics play a crucial role in evaluating fairness and performance in machine learning models. This class aims to enhance understanding by explaining what a metric is and, if needed, how it is calculated. It generates human-readable explanations for various metrics, making it easier for users to interpret and assess the significance of the metric values. These explanations are especially valuable when dealing with fairness metrics, as they often have specific interpretations beyond traditional accuracy.
- This class contains text explanations for all metric values regardless of which subclass they appear in. This will raise an error if the metric does not apply (e.g. calling `true_positive_rate` if `type(metric) == DatasetMetric`).


**Initialization**:
Initialize a `MetricExplainer` object.
```python
__init__(metric)
```
**Parameters**:
- `metric` (*Metric*): The metric parameter is the metric to be explained. 

Metrics are fundamental to understanding the performance and fairness of machine learning models. By providing a specific metric as an argument during initialization, the MetricTextExplainer object will generate explanations related to that metric.

**Methods**:
The MetricTextExplainer class provides explanations for a wide range of metrics, making it a versatile tool for understanding metric values in the context of fairness and performance assessment. Some of the key metrics and methods available in this class include:

1. `accuracy`
2. `average_abs_odds_difference`
3. `average_odds_difference`
4. `between_all_groups_coefficient_of_variation`
5. `between_all_groups_generalized_entropy_index`
6. `between_all_groups_theil_index`
7. `between_group_coefficient_of_variation`
8. `between_group_generalized_entropy_index`
9. `between_group_theil_index`
10. `coefficient_of_variation`
11. `consistency`
12. `disparate_impact`
13. `equal_opportunity_difference`
14. `error_rate`
15. `error_rate_difference`
16. `error_rate_ratio`
17. `false_discovery_rate` 
18. `false_discovery_rate_difference`
19. `false_discovery_rate_ratio`
20. `false_negative_rate`
21. `false_negative_rate_difference`
22. `false_negative_rate_ratio`
23. `false_omission_rate`
24. `false_omission_rate_ratio`
25. `false_positive_rate`
26. `false_positive_rate_difference`
27. `false_positive_rate_ratio`
28. `falses_omission_rate_difference`
29. `generalized_entropy_index`
30. `mean_difference`
31. `negative_predictive_value`
32. `num_false_negatives`
33. `num_false_positives`
34. `num_instances`
35. `num_negatives`
36. `num_positives`
37. `num_pred_negatives`
38. `num_pred_positives`
39. `num_true_negatives`
40. `num_true_positives`
41. `positive_predictive_value`
42. `power`
43. `precision`
44. `recall`
45. `sensitivity`
46. `specificity`
47. `statistical_parity_difference`
48. `theil_index`
49. `true_negative_rate`
50. `true_positive_rate`
51. `true_positive_rate_difference`

Each of these methods provides an explanation specific to the corresponding metric. When you initialize a MetricTextExplainer object with a particular metric and call one of these methods, it will return a text explanation of the metric value.

The MetricTextExplainer class serves as a valuable tool for users to gain insights into the significance and implications of various fairness and performance metrics in machine learning models.


#### 2.MetricJSONExplainer
**Class**: `aif360.explainers.MetricJSONExplainer`(*metric*)
**Description**:
- Class for explaining metric values in JSON format.
- These briefly explain what a metric is and/or how it is calculated unless it is obvious (e.g. accuracy) and print the value.
- This class contains JSON explanations for all metric values regardless of which subclass they appear in. This will raise an error if the metric does not apply (e.g. calling `true_positive_rate` if `type(metric) == DatasetMetric`).

**Initialization**:
Initialize a `MetricExplainer` object.


**Parameters**:
- `metric` (*Metric*): The metric parameter is the metric to be explained. 
- Metrics are crucial for evaluating the performance and fairness of machine learning models. By providing a specific metric as an argument during initialization, the MetricJSONExplainer object will generate JSON explanations related to that metric.

**Methods**:

The MetricJSONExplainer class provides explanations for a wide range of metrics in JSON format, making it a versatile tool for understanding metric values in the context of fairness and performance assessment. Some of the key metrics and methods available in this class include:


1. `accuracy`
2. `average_abs_odds_difference`
3. `average_odds_difference`
4. `between_all_groups_coefficient_of_variation`
5. `between_all_groups_generalized_entropy_index`
6. `between_all_groups_theil_index`
7. `between_group_coefficient_of_variation`
8. `between_group_generalized_entropy_index`
9. `between_group_theil_index`
10. `coefficient_of_variation`
11. `consistency`
12. `disparate_impact`
13. `equal_opportunity_difference`
14. `error_rate`
15. `error_rate_difference`
16. `error_rate_ratio`
17. `false_discovery_rate` 
18. `false_discovery_rate_difference`
19. `false_discovery_rate_ratio`
20. `false_negative_rate`
21. `false_negative_rate_difference`
22. `false_negative_rate_ratio`
23. `false_omission_rate`
24. `false_omission_rate_ratio`
25. `false_positive_rate`
26. `false_positive_rate_difference`
27. `false_positive_rate_ratio`
28. `falses_omission_rate_difference`
29. `generalized_entropy_index`
30. `mean_difference`
31. `negative_predictive_value`
32. `num_false_negatives`
33. `num_false_positives`
34. `num_instances`
35. `num_negatives`
36. `num_positives`
37. `num_pred_negatives`
38. `num_pred_positives`
39. `num_true_negatives`
40. `num_true_positives`
41. `positive_predictive_value`
42. `power`
43. `precision`
44. `recall`
45. `sensitivity`
46. `specificity`
47. `statistical_parity_difference`
48. `theil_index`
49. `true_negative_rate`
50. `true_positive_rate`
51. `true_positive_rate_difference`

---
---

## Datasets

- Base Classes
- Common Datasets

### 1. Base Classes

- `datasets.Dataset`(***kwargs*):	Abstract base class for datasets.
- `datasets.StructuredDataset`(*df, label_names, …)*:	Base class for all structured datasets.
- `datasets.BinaryLabelDataset`(*[…]*):	Base class for all structured datasets with binary labels.
- `datasets.StandardDataset`(*df, label_name, …*):	Base class for every BinaryLabelDataset provided out of the box by aif360.
- `datasets.RegressionDataset`(*df, dep_var_name, …*):	Base class for regression datasets.

#### 1. aif360.datsets.Dataset
**Class**:`aif360.datasets.Dataset`(***kwargs*)

**Description**:
- The Dataset class serves as an abstract base class for datasets in AIF360. 
- Datasets are fundamental to the machine learning process, and this class provides a common interface and functionality for working with various types of datasets, particularly those used for fairness-aware machine learning.

**Methods**:
- `copy`	- Convenience method to return a copy of this dataset.
- `export_dataset`	- Save this Dataset to disk.
- `split`	- Split this dataset into multiple partitions.
- `validate_dataset`	- Error checking and type validation.


**Methods Explanation**:
1. **`copy`**(*deepcopy=False*) : The copy method is a convenience function to return a copy of the dataset. It allows you to create a new dataset that contains the same data and metadata as the original dataset. You can choose whether to create a deep copy (copying the data and metadata) or a shallow copy (copying the metadata only).

    **Parameters**
    - `deepcopy` (*bool, optional*): If True, the method creates a deep copy of the dataset, including both the data and metadata. If False, it creates a shallow copy, copying only the metadata.

    **Returns**:
        `Dataset`: A new dataset with fields copied from the original object, and metadata set accordingly.

2. **`export_dataset`**(): The export_dataset method allows you to save the dataset to disk. This is useful for persisting datasets for future use or sharing with others.

3. **`split`**(*num_or_size_splits, shuffle=False*): The split method is used to split the dataset into multiple partitions or folds. This can be helpful for tasks like cross-validation, where you want to create training and testing subsets of the dataset.

    **Parameters**
    - `num_or_size_splits` (*array or int*) – If `num_or_size_splits` is an int, k, the value is the number of equal-sized folds to make (if k does not evenly divide the dataset these folds are approximately equal-sized). If `num_or_size_splits` is an array of type int, the values are taken as the indices at which to split the dataset. If the values are floats (< 1.), they are considered to be fractional proportions of the dataset at which to split.
    - `shuffle` (*bool, optional*): If True, the method randomly shuffles the dataset before splitting.

    **Returns**:
    - `list`(*Dataset*): A list of dataset splits. The number of splits depends on the num_or_size_splits parameter.

4. **`validate_dataset`**(): The validate_dataset method is responsible for error checking and type validation of the dataset. It ensures that the dataset adheres to the expected structure and data types, helping to prevent issues that might arise during data processing and modeling.


#### 2. aif360.datsets.StructuredDataset
**Class**:`aif360.datasets.StructuredDataset`(*df, label_names, protected_attribute_names, instance_weights_name=None, scores_names=[], unprivileged_protected_attributes=[], privileged_protected_attributes=[], metadata=None*)

**Description**: 
- Base class for all structured datasets.
- A StructuredDataset requires data to be stored in numpy.ndarray objects with dtype as float64.

    **Variables**:
    - **features** (*numpy.ndarray*) – Dataset features for each instance.
    - **labels** (*numpy.ndarray*) – Generic label corresponding to each instance (could be ground-truth, predicted, cluster assignments, etc.).
    - **scores** (*numpy.ndarray*) – Probability score associated with each label. Same shape as labels. Only valid for binary labels (this includes one-hot categorical labels as well).
    - **protected_attributes** (*numpy.ndarray*) – A subset of features for which fairness is desired.
    - **feature_names** (*list(str)*) – Names describing each dataset feature.
    - **label_names** (*list(str)*) – Names describing each label.
    - **protected_attribute_names** (*list(str)*) – A subset of feature_names corresponding to protected_attributes.
    - **privileged_protected_attributes** (*list(numpy.ndarray)*) – A subset of protected attribute values which are considered privileged from a fairness perspective.
    - **unprivileged_protected_attributes** (*list(numpy.ndarray)*) – The remaining possible protected attribute values which are not included in privileged_protected_attributes.
    - **instance_names** (*list(str)*) – Indentifiers for each instance. Sequential integers by default.
    - **instance_weights** (*numpy.ndarray*) – Weighting for each instance. All equal (ones) by default. Pursuant to standard practice in social science data, 1 means one person or entity. These weights are hence person or entity multipliers (see: https://www.ibm.com/support/knowledgecenter/en/SS3RA7_15.0.0/com.ibm.spss.modeler.help/netezza_decisiontrees_weights.htm) These weights may not be normalized to sum to 1 across the entire dataset, rather the nominal (default) weight of each entity/record in the data is 1. This is similar in spirit to the person weight in census microdata samples. https://www.census.gov/programs-surveys/acs/technical-documentation/pums/about.html
    - **ignore_fields** (*set(str)*) – Attribute names to ignore when doing equality comparisons. Always at least contains 'metadata'.
    - **metadata** (*dict*) –Details about the creation of this dataset. For example:
    
    ```bash
    {
        'transformer': 'Dataset.__init__',
        'params': kwargs,
        'previous': None
    }
    ```
**Initialization**:
```python
__init__(df, label_names, protected_attribute_names, instance_weights_name=None, scores_names=[], unprivileged_protected_attributes=[], privileged_protected_attributes=[], metadata=None)
```

**Parameters**:
- `df` (*pandas.DataFrame*) – Input DataFrame with features, labels, and protected attributes. Values should be preprocessed to remove NAs and make all data numerical. Index values are taken as instance names.
- `label_names` (*iterable*) – Names of the label columns in `df`.
- `protected_attribute_names` (*iterable*) – List of names corresponding to protected attribute columns in `df`.
- `instance_weights_name` (*optional*) – Column name in df corresponding to instance weights. If not provided, `instance_weights` will be all set to 1.
- `unprivileged_protected_attributes` (*optional*) – If not provided, all but the highest numerical value of each protected attribute will be considered not privileged.
- `privileged_protected_attributes` (*optional*) – If not provided, the highest numerical value of each protected attribute will be considered privileged.
- `metadata` (*optional*) – Additional metadata to append.

**Raises**:	
- `TypeError` – Certain fields must be np.ndarrays as specified in the class description.
- `ValueError` – ndarray shapes must match.


**Methods**:
- `align_datasets`	
- `convert_to_dataframe`
- `copy`
- `export_dataset`	
- `import_dataset`	
- `split`
- `subset`
- `temporarily_ignore`	
- `validate_dataset`

**Methods Explanation**:
1. **`align_datasets`**(*other*):
    - Align the other dataset features, labels and protected_attributes to this dataset.

    **Parameters**:	`other` (*StructuredDataset*) – Other dataset that needs to be aligned
    
    **Returns**:	*StructuredDataset* – New aligned dataset
    
2. **`convert_to_dataframe`**(*de_dummy_code=False, sep='=', set_category=True*):
    - Convert the StructuredDataset to a pandas.DataFrame.

    **Parameters**:	
    - `de_dummy_code` (*bool*) – Performs de_dummy_coding, converting dummy- coded columns to categories. If `de_dummy_code` is `True` and this dataset contains mappings for label and/or protected attribute values to strings in the `metadata`, this method will convert those as well.
    - `sep` (*char*) – Separator between the prefix in the dummy indicators and the dummy-coded categorical levels.
    - `set_category` (*bool*) – Set the de-dummy coded features to categorical type.

    **Returns**:	
    *(pandas.DataFrame, dict)* –

    - `pandas.DataFrame`: Equivalent dataframe for a dataset. All columns will have only numeric values. The `protected_attributes` field in the dataset will override the values in the `features` field.
    - `dict`: Attributes. Will contain additional information pulled from the dataset such as `feature_names`, `label_names`, `protected_attribute_names`, `instance_names`, `instance_weights`, `privileged_protected_attributes`, `unprivileged_protected_attributes`. 
    The metadata will not be returned.

3. **`copy`**(*deepcopy=False*):
    - Convenience method to return a copy of this dataset.

    **Parameters**:
    - `deepcopy` (*bool, optional*): If True, the method creates a deep copy of the dataset, including both the data and metadata. If False, it creates a shallow copy, copying only the metadata.
    
    **Returns**:
    - *Dataset*: A new dataset with fields copied from the original object, and metadata set accordingly.
    
    
4. **`export_dataset`**(*export_metadata=False*):
    - Export the dataset and supporting attributes (***The preferred file format is HDF***).

    **Parameters**: `export_metadata` (*bool, optional*)- If True, the method exports metadata along with the dataset.
    
    **Returns**: *str*- The exported dataset as a string 

5. **`import_dataset`**(*import_metadata=False*):
    - Import the dataset and supporting attributes (***The preferred file format is HDF***)

    **Parameters**: `import_metadata` (*bool, optional*) - If True, the method imports metadata along with the dataset.
    
    **Returns**: *StructuredDataset* -  The imported dataset.
    
    
6. **`split`**(*num_or_size_splits, shuffle=False, seed=None*):
    - Split this dataset into multiple partitions.

    **Parameters**:
    - `num_or_size_splits` (*array or int*): If `num_or_size_splits` is an int, k, the value is the number of equal-sized folds to make (if k does not evenly divide the dataset these folds are approximately equal-sized). If `num_or_size_splits` is an array of type int, the values are taken as the indices at which to split the dataset. If the values are floats (< 1.), they are considered to be fractional proportions of the dataset at which to split.
    - `shuffle` (*bool, optional*): If True, the method randomly shuffles the dataset before splitting.
    - `seed` (*int or array_like, optional*): Takes the same argument as `numpy.random.seed()`.

    **Returns**:
    - *list*: Splits. Contains k or `len(num_or_size_splits) + 1` datasets depending on `num_or_size_splits`.


7. **`subset`**(indexes):
    - Subset of dataset based on position :param indexes: iterable which contains row indexes.

    **Parameters** :`indexes` (*iterable*)- An iterable containing row indexes that specify the subset of the dataset.
    
    **Returns**: *StructuredDataset*- A subset of the dataset based on the specified indexes.


8. **`temporarily_ignore`**(*'features', 'labels'*):
    - Temporarily add the fields provided to `ignore_fields`.
    - To be used in a `with` statement. Upon completing the with block, ignore_fields is restored to its original value.

    **Parameters**:	
    ****fields*** – Additional fields to ignore for equality comparison within the scope of this context manager, e.g. `temporarily_ignore('features', 'labels')`. The temporary `ignore_fields` attribute is the union of the old attribute and the set of these fields.
    
    **Examples**:
    ```python
    sd = StructuredDataset(...)
    modified = sd.copy()
    modified.labels = sd.labels + 1
    assert sd != modified
    with sd.temporarily_ignore('labels'):
        assert sd == modified
    assert 'labels' not in sd.ignore_fields
    ```

9. **`validate_dataset`**():
    - Error checking and type validation.
    
    **Parameters** : None
    
    **Returns** : None









#### 3. aif360.datsets.BinaryLabelDataset
**Class**:`aif360.datasets.BinaryLabelDataset`(_favorable_label=1.0, unfavorable_label=0.0, **kwargs_)

**Description**: Base class for all structured datasets with binary labels.

**Initialization**:
```python
__init__(favorable_label=1.0, unfavorable_label=0.0, **kwargs)
```
**Parameters**:	
- `favorable_label` (*float*) – Label value which is considered favorable (i.e. “positive”).
- `unfavorable_label` (*float*) – Label value which is considered unfavorable (i.e. “negative”).
- `**kwargs` – StructuredDataset arguments.

**Methods**:
- `align_datasets`	Align the other dataset features, labels and protected_attributes to this dataset.
- `convert_to_dataframe`	Convert the StructuredDataset to a pandas.DataFrame.
- `copy	Convenience` method to return a copy of this dataset.
- `export_dataset`	Export the dataset and supporting attributes TODO: The preferred file format is HDF
- `import_dataset`	Import the dataset and supporting attributes TODO: The preferred file format is HDF
- `split`	Split this dataset into multiple partitions.
- `subset`	Subset of dataset based on position :param indexes: iterable which contains row indexes
- `temporarily_ignore`	Temporarily add the fields provided to ignore_fields.
- `validate_dataset`	Error checking and type validation.




**Methods Explanation**:
1. **`align_datasets`**: Align the other dataset features, labels, and protected_attributes to this dataset.
   
   **Parameters**: - `other` (*StructuredDataset*) – Other dataset that needs to be aligned.
    
    **Returns**: - `StructuredDataset` – New aligned dataset.

2. **`convert_to_dataframe`**: Convert the StructuredDataset to a pandas.DataFrame.
   
   **Parameters**:
     - `de_dummy_code` (*bool*) – Performs de_dummy_coding, converting dummy-coded columns to categories. If de_dummy_code is True and this dataset contains mappings for label and/or protected attribute values to strings in the metadata, this method will convert those as well.
     - `sep` (*char*) – Separator between the prefix in the dummy indicators and the dummy-coded categorical levels.
     - `set_category` (*bool*) – Set the de-dummy coded features to categorical type.
    
    **Returns**:
     - `(pandas.DataFrame, dict)`:
       - `pandas.DataFrame`: Equivalent dataframe for a dataset. All columns will have only numeric values. The protected_attributes field in the dataset will override the values in the features field.
       - `dict`: Attributes. Will contain additional information pulled from the dataset such as feature_names, label_names, protected_attribute_names, instance_names, instance_weights, privileged_protected_attributes, unprivileged_protected_attributes. The metadata will not be returned.

3. **`copy`**: Convenience method to return a copy of this dataset.
   
   **Parameters**:- `deepcopy` (*bool, optional*) – deepcopy() this dataset if True, shallow copy otherwise.
   
   **Returns**: - `Dataset` – A new dataset with fields copied from this object and metadata set accordingly.

4. **`export_dataset`**: Export the dataset and supporting attributes. (TODO: The preferred file format is HDF)
   
   **Parameters**: - `export_metadata` (*bool, optional*) – If True, export metadata along with the dataset.
  
   **Returns**: None

5. **`import_dataset`**:Import the dataset and supporting attributes. (TODO: The preferred file format is HDF)
   
   **Parameters**:- `import_metadata` (*bool, optional*) – If True, import metadata along with the dataset.
   
   **Returns**: None

6. **`split`**: Split this dataset into multiple partitions.
   
   **Parameters**:
     - `num_or_size_splits` (*array or int*) – If num_or_size_splits is an int, k, the value is the number of equal-sized folds to make (if k does not evenly divide the dataset these folds are approximately equal-sized). If num_or_size_splits is an array of type int, the values are taken as the indices at which to split the dataset. If the values are floats (< 1.), they are considered to be fractional proportions of the dataset at which to split.
     - `shuffle` (*bool, optional*) – Randomly shuffle the dataset before splitting.
     - `seed` (*int or array_like*) – Takes the same argument as numpy.random.seed().
   
    **Returns**:
     - `list` – Splits. Contains k or len(num_or_size_splits) + 1 datasets depending on num_or_size_splits.

7. **`subset`**: Subset of the dataset based on position.
   
   **Parameters**: - `indexes` (iterable) – An iterable which contains row indexes.
   
   **Returns**:- `StructuredDataset` – Subset of the dataset based on indexes.

8. **`temporarily_ignore`**:Temporarily add the fields provided to ignore_fields.
   
   **Parameters**:- `fields` – Additional fields to ignore for equality comparison within the scope of this context manager, e.g., temporarily_ignore('features', 'labels'). The temporary ignore_fields attribute is the union of the old attribute and the set of these fields.
   
   **Returns**: None

9. **`validate_dataset`**:Error checking and type validation.
   
   **Parameters**: None
   
   **Raises**:	
        - ValueError – `labels` must be shape [n, 1].
        - ValueError – `favorable_label` and `unfavorable_label` must be the only values present in labels.


#### 4. aif360.datsets.StandardDataset
**Class**:`aif360.datasets.StandardDataset`(*df, label_name, favorable_classes, protected_attribute_names, privileged_classes, instance_weights_name='', scores_name='', categorical_features=[], features_to_keep=[], features_to_drop=[], na_values=[], custom_preprocessing=None, metadata=None*)

**Description**:
    - Base class for every BinaryLabelDataset provided out of the box by aif360.
    - It is not strictly necessary to inherit this class when adding custom datasets but it may be useful.
    - This class is very loosely based on code from https://github.com/algofairness/fairness-comparison.
    
**Initialization**:
```python
__init__(df, label_name, favorable_classes, protected_attribute_names, privileged_classes, instance_weights_name='', scores_name='', categorical_features=[], features_to_keep=[], features_to_drop=[], na_values=[], custom_preprocessing=None, metadata=None)
```
Subclasses of StandardDataset should perform the following before calling `super().__init__`:
1. Load the dataframe from a raw file.
Then, this class will go through a standard preprocessing routine which:
2. (optional) Performs some dataset-specific preprocessing (e.g. renaming columns/values, handling missing data).
3. Drops unrequested columns (see features_to_keep and features_to_drop for details).
4. Drops rows with NA values.
5. Creates a one-hot encoding of the categorical variables.
6. Maps protected attributes to binary privileged/unprivileged values (1/0).
7. Maps labels to binary favorable/unfavorable labels (1/0).

**Parameters**:	
- `df` (_pandas.DataFrame_) – DataFrame on which to perform standard processing.
- `label_name` – Name of the label column in `df`.
- `favorable_classes` (_list or function_) – Label values which are considered favorable or a boolean function which returns `True` if favorable. All others are unfavorable. Label values are mapped to 1 (favorable) and 0 (unfavorable) if they are not already binary and numerical.
- `protected_attribute_names` (_list_) – List of names corresponding to protected attribute columns in `df`.
- `privileged_classes` (_list(list or function)_) – Each element is a list of values which are considered privileged or a boolean function which return `True` if privileged for the corresponding column in `protected_attribute_names`. All others are unprivileged. Values are mapped to 1 (privileged) and 0 (unprivileged) if they are not already numerical.
- `instance_weights_name` (_optional_) – Name of the instance weights column in `df`.
- `categorical_features` (_optional, list_) – List of column names in the DataFrame which are to be expanded into one-hot vectors.
- `features_to_keep` (_optional, list_) – Column names to keep. All others are dropped except those present in `protected_attribute_names`, `categorical_features`, `label_name` or `instance_weights_name`. Defaults to all columns if not provided.
- `features_to_drop` (_optional, list_) – Column names to drop. Note: this overrides `features_to_keep`.
- `na_values` (_optional_) – Additional strings to recognize as NA. See pandas.read_csv() for details.
- `custom_preprocessing` (_function_) – A function object which acts on and returns a DataFrame (f: DataFrame -> DataFrame). If `None`, no extra preprocessing is applied.
- `metadata` (*optional*) – Additional metadata to append.


**Methods**:
- `align_datasets`	
- `convert_to_dataframe`	
- `copy`	
- `export_dataset`	
- `import_dataset`	
- `split`	
- `subset`	
- `temporarily_ignore`	
- `validate_dataset`	

**Methods Explanation**:

1. **`align_datasets`** - Align the other dataset features, labels and protected_attributes to this dataset.

    **Parameters**: - `other (StructuredDataset)`: Other dataset that needs to be aligned.
    
    **Return Type**: - `StructuredDataset`: New aligned dataset.

2. **`convert_to_dataframe`** - Convert the StructuredDataset to a `pandas.DataFrame`.

    **Parameters**:
    - `de_dummy_code (bool)`: Performs de-dummy coding, converting dummy-coded columns to categories. If `de_dummy_code` is `True` and this dataset contains mappings for label and/or protected attribute values to strings in the metadata, this method will convert those as well.
    - `sep (char)`: Separator between the prefix in the dummy indicators and the dummy-coded categorical levels.
    - `set_category (bool)`: Set the de-dummy coded features to categorical type.
    
    **Return Type**:
    - `(pandas.DataFrame, dict)`: A tuple containing:
    - `pandas.DataFrame`: Equivalent dataframe for a dataset. All columns will have only numeric values. The protected_attributes field in the dataset will override the values in the features field.
    - `dict`: Attributes. Will contain additional information pulled from the dataset such as feature_names, label_names, protected_attribute_names, instance_names, instance_weights, privileged_protected_attributes, unprivileged_protected_attributes. The metadata will not be returned.

3. **`copy`** - Convenience method to return a copy of this dataset.

    **Parameters**: - `deepcopy (bool, optional)`: If `True`, the method creates a deep copy of the dataset, including both the data and metadata. If `False`, it creates a shallow copy, copying only the metadata.

    **Return Type**:
    - `Dataset`: A new dataset with fields copied from the original object, and metadata set accordingly.

4. **`export_dataset`** - Export the dataset and supporting attributes (***The preferred file format is HDF***)

    **Parameters**:
    - `export_metadata (bool, optional)`: If `True`, the method exports metadata along with the dataset.

    **Return Type**:
    - `str`: The exported dataset as a string (TODO: The preferred file format is HDF).

5. **`import_dataset`** - Import the dataset and supporting attributes (***The preferred file format is HDF***)

    **Parameters**:
    - `import_metadata (bool, optional)`: If `True`, the method imports metadata along with the dataset.

    **Return Type**:
    - `StructuredDataset`: The imported dataset.

6. **`split`** - Split this dataset into multiple partitions.

    **Parameters**:
    - `num_or_size_splits (array or int)`: If it's an integer `k`, it represents the number of equal-sized folds to create. If it's an array of integers, the values in the array are taken as the indices at which to split the dataset. If the values in the array are floats less than 1, they are considered as fractional proportions of the dataset at which to split.
    - `shuffle (bool, optional)`: If `True`, the method randomly shuffles the dataset before splitting.
    - `seed (int or array_like, optional)`: Takes the same argument as numpy.random.seed().

    **Return Type**:
    - `list`: Splits. Contains `k` or `len(num_or_size_splits) + 1` datasets depending on `num_or_size_splits`.

7. **`subset`** - Subset of dataset based on position :param indexes: iterable which contains row indexes.

    **Parameters**:
    - `indexes (iterable)`: An iterable containing row indexes that specify the subset of the dataset.

    **Return Type**:
    - `StructuredDataset`: A subset of the dataset based on the specified indexes.

8. **`temporarily_ignore`** - Temporarily add the fields provided to ignore_fields.

    **Parameters**:
    - `*fields`: Additional fields to ignore for equality comparison within the scope of this context manager, e.g., `temporarily_ignore('features', 'labels')`. The temporary `ignore_fields` attribute is the union of the old attribute and the set of these fields.

    **Return Type**:
    - Context manager: This method is used as a context manager with the `with` statement.

9. **`validate_dataset`** - Error checking and type validation.

    **Parameters**: - None
    
    **Return Type**: - None


#### 5. aif360.datsets.RegressionDataset
**Class**: `aif360.datasets.RegressionDataset`(_df, dep_var_name, protected_attribute_names, privileged_classes, instance_weights_name='', categorical_features=[], na_values=[], custom_preprocessing=None, metadata=None_)
**Description**:
- Base class for regression datasets.

**Initialization**:
```python
__init__(df, dep_var_name, protected_attribute_names, privileged_classes, instance_weights_name='', categorical_features=[], na_values=[], custom_preprocessing=None, metadata=None)
```
Subclasses of RegressionDataset should perform the following before calling `super().__init__`:

1. Load the dataframe from a raw file.
    Then, this class will go through a standard preprocessing routine which:
2. (optional) Performs some dataset-specific preprocessing (e.g., renaming columns/values, handling missing data).
3. Drops rows with NA values.
4. Creates a one-hot encoding of the categorical variables.
5. Maps protected attributes to binary privileged/unprivileged values (1/0).
6. Normalizes df values.


**Parameters**:
- `df` (pandas.DataFrame) – DataFrame on which to perform standard processing.
- `dep_var_name` – Name of the dependent variable column in df.
- `protected_attribute_names` (list) – List of names corresponding to protected attribute columns in df.
- `privileged_classes` (list(list or function)) – Each element is a list of values which are considered privileged or a boolean function which returns True if privileged for the corresponding column in protected_attribute_names. All others are unprivileged. Values are mapped to 1 (privileged) and 0 (unprivileged) if they are not already numerical.
- `instance_weights_name` (optional) – Name of the instance weights column in df.
- `categorical_features` (optional, list) – List of column names in the DataFrame which are to be expanded into one-hot vectors.
- `na_values` (optional) – Additional strings to recognize as NA. See pandas.read_csv() for details.
- `custom_preprocessing` (function) – A function object which acts on and returns a DataFrame (f: DataFrame -> DataFrame). If None, no extra preprocessing is applied.
- `metadata` (optional) – Additional metadata to append.

**Methods**:
- `align_datasets`
- `convert_to_dataframe`
- `copy`
- `export_dataset` 
- `import_dataset`
- `split`
- `subset`
- `temporarily_ignore`
`validate_dataset`



**Methods Explanation**:
1. **`align_datasets`**: Align the other dataset features, labels, and protected_attributes to this dataset.
   
   **Parameters**:
    - `other` (StructuredDataset) – Other dataset that needs to be aligned.
  
    **Returns**:
    - `StructuredDataset` – New aligned dataset.

2. **`convert_to_dataframe`**: Convert the StructuredDataset to a pandas.DataFrame.
   
   **Parameters**:
     - `de_dummy_code` (bool) – Performs de_dummy_coding, converting dummy-coded columns to categories. If de_dummy_code is True and this dataset contains mappings for label and/or protected attribute values to strings in the metadata, this method will convert those as well.
     - `sep` (char) – Separator between the prefix in the dummy indicators and the dummy-coded categorical levels.
     - `set_category` (bool) – Set the de-dummy coded features to categorical type.

   **Returns**:
     - `(pandas.DataFrame, dict)`:
       - `pandas.DataFrame`: Equivalent dataframe for a dataset. All columns will have only numeric values. The protected_attributes field in the dataset will override the values in the features field.
       - `dict`: Attributes. Will contain additional information pulled from the dataset such as feature_names, label_names, protected_attribute_names, instance_names, instance_weights, privileged_protected_attributes, unprivileged_protected_attributes. The metadata will not be returned.

3. **`copy`**: Convenience method to return a copy of this dataset.
   
   **Parameters**:
     - `deepcopy` (bool, optional) – deepcopy() this dataset if True, shallow copy otherwise.
  
    **Returns**:
     - `Dataset` – A new dataset with fields copied from this object and metadata set accordingly.

4. **`export_dataset`**: Export the dataset and supporting attributes. (TODO: The preferred file format is HDF)
   
   **Parameters**:
     - `export_metadata` (bool, optional) – If True, export metadata along with the dataset.
   
    **Returns**: None

5. **`import_dataset`**: Import the dataset and supporting attributes. (TODO: The preferred file format is HDF)
   
   **Parameters**:
     - `import_metadata` (bool, optional) – If True, import metadata along with the dataset.
  
    **Returns**: None

6. **`split`**: Split this dataset into multiple partitions.
   
   **Parameters**:
     - `num_or_size_splits` (array or int) – If num_or_size_splits is an int, k, the value is the number of equal-sized folds to make (if k does not evenly divide the dataset these folds are approximately equal-sized). If num_or_size_splits is an array of type int, the values are taken as the indices at which to split the dataset. If the values are floats (< 1.), they are considered to be fractional proportions of the dataset at which to split.
     - `shuffle` (bool, optional) – Randomly shuffle the dataset before splitting.
     - `seed` (int or array_like) – Takes the same argument as `numpy.random.seed()`. 
   
   **Returns**:
     - `list` – Splits. Contains k or len(num_or_size_splits) + 1 datasets depending on num_or_size_splits.

7. **`subset`**: Subset of the dataset based on position.
   
   **Parameters**:
     - `indexes` (iterable) – An iterable which contains row indexes.
    
   **Returns**:
     - `StructuredDataset` – Subset of the dataset based on indexes.

8. **`temporarily_ignore`**: Temporarily add the fields provided to ignore_fields.
   
   **Parameters**:
     - `*fields` – Additional fields to ignore for equality comparison within the scope of this context manager, e.g., temporarily_ignore('features', 'labels'). The temporary ignore_fields attribute is the union of the old attribute and the set of these fields.
   
    **Returns**: None

9. **`validate_dataset`**: Error checking and type validation.
   
   **Parameters**: None
   
   **Returns**: None


### 2. Common Datasets

- `datasets.AdultDataset`(*[label_name, …]*)    :- 	Adult Census Income Dataset.
- `datasets.BankDataset`(*[label_name, …]*)     :-	Bank marketing Dataset.
- `datasets.CompasDataset`(*[label_name, …]*)   :-	ProPublica COMPAS Dataset.
- `datasets.GermanDataset`(*[label_name, …]*)   :-	German credit Dataset.
- `datasets.LawSchoolGPADataset`(*[dep_var_name, …]*)   :-	Law School GPA dataset.
- `datasets.MEPSDataset19`(*[label_name, …]*)   :-	MEPS Dataset.
- `datasets.MEPSDataset20`(*[label_name, …]*)   :-	MEPS Dataset.
- `datasets.MEPSDataset21`(*[label_name, …]*)   :-	MEPS Dataset.


#### MEPS Dataset?
**Title**: Understanding MEPS (Medical Expenditure Panel Survey)

**Overview**: MEPS (Medical Expenditure Panel Survey) is a comprehensive survey conducted in the United States to collect data on healthcare utilization, expenditures, insurance coverage, and health status among the U.S. civilian noninstitutionalized population. It provides valuable insights into healthcare trends, access, costs, and disparities.

**Key Points**:

1. **Purpose**: MEPS is designed to gather data on various aspects of healthcare, making it a vital resource for researchers and policymakers to understand and improve the healthcare system.

2. **Data Collection**: MEPS collects data from a representative sample of households and individuals across the country, covering topics such as doctor visits, hospital stays, prescription medications, health insurance, and more.

3. **Research Applications**: Researchers use MEPS data to:

   - Analyze patterns of healthcare utilization and expenditures.
   - Study the impact of health insurance coverage on healthcare access.
   - Investigate healthcare disparities among different demographic groups.

4. **MEPSDataset21**: In the context of the document, "aif360.datasets.MEPSDataset21" is a specific class or dataset within the AI Fairness 360 (AIF360) framework tailored for working with MEPS data. It offers tools and methods for analyzing and processing healthcare-related data while considering fairness and bias mitigation.

**Resources**: You can access MEPS data and related documentation through the Agency for Healthcare Research and Quality (AHRQ) website.



#### 1. aif360.datasets.AdultDataset

**Class**: `aif360.datasets.AdultDataset`(*label_name='income-per-year', favorable_classes=['>50K', '>50K.'], protected_attribute_names=['race', 'sex'], privileged_classes=[['White'], ['Male']], instance_weights_name=None, categorical_features=['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'native-country'], features_to_keep=[], features_to_drop=['fnlwgt'], na_values=['?'], custom_preprocessing=None, metadata={'label_maps': [{1.0: '>50K', 0.0: '<=50K'}], 'protected_attribute_maps': [{1.0: 'White', 0.0: 'Non-white'}, {1.0: 'Male', 0.0: 'Female'}]}*)

See aif360/data/raw/adult/README.md.

See `StandardDataset` for a description of the arguments.

   - **Examples**:
     - The following will instantiate a dataset which uses the fnlwgt feature:

       ```python
       >>> from aif360.datasets import AdultDataset
       >>> ad = AdultDataset(instance_weights_name='fnlwgt', features_to_drop=[])
       WARNING:root:Missing Data: 3620 rows removed from dataset.
       >>> not np.all(ad.instance_weights == 1.)
       True
       ```

     - To instantiate a dataset which utilizes only numerical features and a single protected attribute, run:

       ```python
       >>> single_protected = ['sex']
       >>> single_privileged = [['Male']]
       >>> ad = AdultDataset(protected_attribute_names=single_protected, privileged_classes=single_privileged, categorical_features=[], features_to_keep=['age', 'education-num'])
       >>> print(ad.feature_names)
       ['education-num', 'age', 'sex']
       >>> print(ad.label_names)
       ['income-per-year']
       ```

     - In some cases, it may be useful to keep track of a mapping from float -> str for protected attributes and/or labels. If our use case differs from the default, we can modify the mapping stored in metadata:

       ```python
       >>> label_map = {1.0: '>50K', 0.0: '<=50K'}
       >>> protected_attribute_maps = [{1.0: 'Male', 0.0: 'Female'}]
       >>> ad = AdultDataset(protected_attribute_names=['sex'], categorical_features=['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'native-country', 'race'], privileged_classes=[['Male']], metadata={'label_map': label_map, 'protected_attribute_maps': protected_attribute_maps})
       ```

**Methods**:

1. **`align_datasets`**: Aligns the other dataset features, labels, and protected_attributes to this dataset.
   
   **Parameters**:- `other_dataset` (*StructuredDataset*): The dataset to align with this dataset.
   
   **Returns**:- `StructuredDataset`: A new dataset with aligned features, labels, and protected attributes.

2. **`convert_to_dataframe`**: Converts the dataset into a pandas DataFrame.
   
   **Parameters**: - None
   
   **Returns**:
     - `pandas.DataFrame`: A pandas DataFrame representation of the dataset.

3. **`copy`**: Creates a copy of this dataset.
   
   **Parameters**:- None
   
   **Returns**:- `AdultDataset`: A copy of the current dataset.

4. **`export_dataset`**: Exports the dataset to a specified file.
   
   **Parameters**:- `file_path` (str): The path to the file where the dataset should be exported.
   
   **Returns**:- None

6. **`import_dataset`**: Imports a dataset from a file.
   
   **Parameters**:- `file_path` (str): The path to the file from which the dataset should be imported.
   
   **Returns**:- `AdultDataset`: A new instance of the `AdultDataset` class with data imported from the specified file.

7. **`split`**:Splits the dataset into multiple partitions.
   
   **Parameters**:
     - `num_partitions` (int): The number of partitions to create.
     - `seed` (int, optional): Seed for randomization (for reproducibility).
   
    **Returns**:
     - `list` of `AdultDataset`: A list of `AdultDataset` instances representing the partitions.

8. **`subset`**: Creates a new dataset that includes only the rows specified by the `indexes` parameter.
   
   **Parameters**:- `indexes` (iterable): An iterable containing row indexes.
   
   **Returns**:- `AdultDataset`: A new dataset that is a subset of the current dataset based on the provided row indexes.

9. **`temporarily_ignore`**: Temporarily adds the fields provided to ignore_fields.
   
   **Parameters**:- `ignore_fields` (list of str): The fields (features, labels, or protected attributes) to temporarily ignore.
   
   **Returns**:- None

10. **`validate_dataset`**: Performs error checking and type validation on the dataset.
    
    **Parameters**:- None
    
    **Returns**:- `dict`: A dictionary containing validation results, including information about missing values and data types.


    > Note that we are now adding race as a categorical_features. Now this information will stay attached to the dataset and can be used for more descriptive visualizations.

#### 2. aif360.datasets.BankDataset

**Class**:`aif360.datasets.BankDataset`(*label_name='y', favorable_classes=['yes'], protected_attribute_names=['age'], privileged_classes=[<function BankDataset.<<*lambda*>>], instance_weights_name=None, categorical_features=['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'day_of_week', 'poutcome'], features_to_keep=[], features_to_drop=[], na_values=['unknown'], custom_preprocessing=None, metadata=None*)
**Description:**;Bank marketing Dataset.

See `StandardDataset` for a description of the arguments.

By default, this code converts the ‘age’ attribute to a binary value where privileged is 25 <= age < 60 and unprivileged is age < 25 or age >= 60 as suggested in Le Quy, Tai, et al. [1].

References

[1]	Le Quy, Tai, et al. “A survey on datasets for fairness‐aware machine
learning.” Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery 12.3 (2022): e1452.

**Methods**:

1. **`align_datasets`**: Aligns the features, labels, and protected attributes of the current dataset with those of another dataset (`other_dataset`). This method ensures that both datasets have the same structure and order of features, labels, and protected attributes.
   
   **Parameters**:- `other_dataset` (StructuredDataset): The dataset to align with this dataset.
   
   **Returns**:- `StructuredDataset`: A new dataset with aligned features, labels, and protected attributes.

2. **`convert_to_dataframe`**:Converts the dataset into a pandas DataFrame for easier data manipulation and analysis. This DataFrame includes all features, labels, and protected attributes.
   
    **Parameters**:- None
    
    **Returns**:- `pandas.DataFrame`: A pandas DataFrame representation of the dataset.

3. **`copy`**:Creates a new instance of the `BankDataset` class that is an exact copy of the current dataset, including all data and metadata.
   
   **Parameters**:- None
   
   **Returns**:- `BankDataset`: A copy of the current dataset.

4. **`export_dataset`**: Exports the dataset to a specified file in a preferred file format (typically HDF). This method allows for saving the dataset to a file for later use or sharing.
   
   **Parameters**:- `file_path` (str): The path to the file where the dataset should be exported.
   
   **Returns**:- None

5. **`import_dataset`**: Imports a dataset from a file in a preferred file format (typically HDF). This method allows for loading a previously saved dataset for analysis.
   
   **Parameters**:`file_path` (str): The path to the file from which the dataset should be imported.
   
   **Returns**:- `BankDataset`: A new instance of the `BankDataset` class with data imported from the specified file.

6. **`split`**:Splits the dataset into multiple partitions for tasks like cross-validation. The `num_partitions` parameter specifies the number of partitions to create, and the `seed` parameter is used for randomization.
   
   **Parameters**:
     - `num_partitions` (int): The number of partitions to create.
     - `seed` (int, optional): Seed for randomization (for reproducibility).

    **Returns**:
     - `list` of `BankDataset`: A list of `BankDataset` instances representing the partitions.

7. **`subset`**:Creates a new dataset that includes only the rows specified by the `indexes` parameter. Useful for selecting specific subsets of data.
   
   **Parameters**:- `indexes` (iterable): An iterable containing row indexes.
   
   **Returns**:- `BankDataset`: A new dataset that is a subset of the current dataset based on the provided row indexes.

8. **`temporarily_ignore`**:Temporarily adds the specified fields to the list of ignored fields, which means these fields will be excluded from certain operations temporarily. This is useful when specific fields need to be excluded for analysis or fairness assessment.
   
   **Parameters**:- `ignore_fields` (list of str): The fields (features, labels, or protected attributes) to temporarily ignore.
   
   **Returns**:- None

9. **`validate_dataset`**: Performs error checking and type validation on the dataset to ensure that it meets the required standards and formats. The method returns a dictionary with validation results.
   
   **Parameters**:- None
   
   **Returns**:- `dict`: A dictionary containing validation results, including information about missing values and data types.


#### 3. aif360.datasets.CompasDataset

**Class**: `aif360.datasets.CompasDataset`(*label_name='two_year_recid', favorable_classes=[0], protected_attribute_names=['sex', 'race'], privileged_classes=[['Female'], ['Caucasian']], instance_weights_name=None, categorical_features=['age_cat', 'c_charge_degree', 'c_charge_desc'], features_to_keep=['sex', 'age', 'age_cat', 'race', 'juv_fel_count', 'juv_misd_count', 'juv_other_count', 'priors_count', 'c_charge_degree', 'c_charge_desc', 'two_year_recid'], features_to_drop=[], na_values=[], custom_preprocessing=<function default_preprocessing>, metadata={'label_maps': [{1.0: 'Did recid.', 0.0: 'No recid.'}], 'protected_attribute_maps': [{0.0: 'Male', 1.0: 'Female'}, {1.0: 'Caucasian', 0.0: 'Not Caucasian'}]}*)

**Description**: ProPublica COMPAS Dataset.

**Parameters**:
- `label_name` (str): The name of the label column in the dataset.
- `favorable_classes` (list of int): The list of favorable class values.
- `protected_attribute_names` (list of str): The names of protected attribute columns.
- `privileged_classes` (list of list): The privileged classes for each protected attribute.
- `instance_weights_name` (str, optional): The name of the instance weights column.
- `categorical_features` (list of str): The names of categorical feature columns.
- `features_to_keep` (list of str): The names of features to keep in the dataset.
- `features_to_drop` (list of str): The names of features to drop from the dataset.
- `na_values` (list, optional): The list of values that should be treated as missing values.
- `custom_preprocessing` (function, optional): Custom preprocessing function to apply to the dataset.
- `metadata` (dict, optional): Additional metadata for the dataset.

**Methods**:

1. **`align_datasets`**:
   - **Parameters**:
     - `dataset` (aif360.datasets.CompasDataset): The dataset to align with this one.
   - **Returns**: None

2. **`convert_to_dataframe`**:
   - **Parameters**: None
   - **Returns**:
     - `pandas.DataFrame`: A DataFrame containing the dataset's data.

3. **`copy`**:
   - **Parameters**: None
   - **Returns**:
     - `aif360.datasets.CompasDataset`: A copy of the dataset.

4. **`export_dataset`**:
   - **Parameters**:
     - `filepath` (str): The file path to export the dataset to.
   - **Returns**: None

5. **`import_dataset`**:
   - **Parameters**:
     - `filepath` (str): The file path to import the dataset from.
   - **Returns**: None

6. **`split`**:
   - **Parameters**:
     - `split_ratio` (float): The ratio by which to split the dataset.
     - `seed` (int, optional): Seed for random number generation (for reproducibility).
   - **Returns**:
     - `tuple` of `aif360.datasets.CompasDataset`: Two new datasets, split according to the specified ratio.

7. **`subset`**:
   - **Parameters**:
     - `indexes` (iterable): An iterable containing row indexes to include in the subset.
   - **Returns**:
     - `aif360.datasets.CompasDataset`: A subset of the dataset based on the provided indexes.

8. **`temporarily_ignore`:**
   - **Parameters**:
     - `ignore_fields` (list or str): The fields to temporarily ignore.
   - **Returns**: None

9. **`validate_dataset`**:
   - **Parameters**: None
   - **Returns**: None

**Examples**: In some cases, it may be useful to keep track of a mapping from float -> str for protected attributes and/or labels. If our use case differs from the default, we can modify the mapping stored in metadata:

```python
label_map = {1.0: 'Did recid.', 0.0: 'No recid.'}
protected_attribute_maps = [{1.0: 'Male', 0.0: 'Female'}]
cd = CompasDataset(protected_attribute_names=['sex'],
privileged_classes=[['Male']], metadata={'label_map': label_map,
'protected_attribute_maps': protected_attribute_maps})
```
Now this information will stay attached to the dataset and can be used for more descriptive visualizations.

> These methods provide essential functionality for working with the `CompasDataset` class, including data manipulation, validation, and export/import capabilities.

#### 4. aif360.datasets.GermanDataset
**Class**: `aif360.datasets.GermanDataset`
**Description**: German credit Dataset.

**Initialization**:

```python
__init__(
    label_name='credit',
    favorable_classes=[1],
    protected_attribute_names=['sex', 'age'],
    privileged_classes=[['male'], <function GermanDataset.<lambda>>],
    instance_weights_name=None,
    categorical_features=['status', 'credit_history', 'purpose', 'savings', 'employment', 'other_debtors', 'property', 'installment_plans', 'housing', 'skill_level', 'telephone', 'foreign_worker'],
    features_to_keep=[],
    features_to_drop=['personal_status'],
    na_values=[],
    custom_preprocessing=<function default_preprocessing>,
    metadata={'label_maps': [{1.0: 'Good Credit', 2.0: 'Bad Credit'}], 'protected_attribute_maps': [{1.0: 'Male', 0.0: 'Female'}, {1.0: 'Old', 0.0: 'Young'}]}
)
```

**Parameters**:

- `label_name` (*str*) – Name of the label column in the dataset.
- `favorable_classes` (*list*) – List of favorable label values.
- `protected_attribute_names` (*list*) – List of protected attribute column names in the dataset.
- `privileged_classes` (*list*) – List of privileged attribute values.
- `instance_weights_name` (*str, optional*) – Name of the instance weights column in the dataset.
- `categorical_features` (*list, optional*) – List of categorical feature column names.
- `features_to_keep` (*list, optional*) – List of feature column names to keep.
- `features_to_drop` (*list, optional*) – List of feature column names to drop.
- `na_values` (*list, optional*) – List of values to recognize as missing data.
- `custom_preprocessing` (*function, optional*) – Custom preprocessing function for the dataset.
- `metadata` (*dict, optional*) – Metadata to attach to the dataset.

**Methods**:

1. **`align_datasets`**:
   - **Parameters**:
     - `dataset` (aif360.datasets.GermanDataset): The dataset to align with this one.
   - **Returns**: None

2. **`convert_to_dataframe`**:
   - **Parameters**: None
   - **Returns**:
     - `pandas.DataFrame`: A DataFrame containing the dataset's data.

3. **`copy`**:
   - **Parameters**: None
   - **Returns**:
     - `aif360.datasets.GermanDataset`: A copy of the dataset.

4. **`export_dataset`**:
   - **Parameters**:
     - `filepath` (str): The file path to export the dataset to.
   - **Returns**: None

5. **`import_dataset`**:
   - **Parameters**:
     - `filepath` (str): The file path to import the dataset from.
   - **Returns**: None

6. **`split`**:
   - **Parameters**:
     - `split_ratio` (float): The ratio by which to split the dataset.
     - `seed` (int, optional): Seed for random number generation (for reproducibility).
   - **Returns**:
     - `tuple` of `aif360.datasets.GermanDataset`: Two new datasets, split according to the specified ratio.

7. **`subset`**:
   - **Parameters**:
     - `indexes` (iterable): An iterable containing row indexes to include in the subset.
   - **Returns**:
     - `aif360.datasets.GermanDataset`: A subset of the dataset based on the provided indexes.

8. **`temporarily_ignore`**:
   - **Parameters**:
     - `ignore_fields` (list or str): The fields to temporarily ignore.
   - **Returns**: None

9. **`validate_dataset`**:
   - **Parameters**: None
   - **Returns**: None

> These methods provide essential functionality for working with the `GermanDataset` class, including data manipulation, validation, and export/import capabilities. Please note that some methods modify the dataset in place (e.g., `align_datasets`, `temporarily_ignore`), while others return new instances or values (e.g., `convert_to_dataframe`, `split`).

**Additional Information**:

- This dataset converts the 'age' attribute to a binary value where privileged is age > 25 and unprivileged is age <= 25 as proposed by Kamiran and Calders [1].

**References**:

[1] F. Kamiran and T. Calders, “Classifying without discriminating,” 2nd International Conference on Computer, Control, and Communication, 2009.

**Examples**:

In some cases, it may be useful to keep track of a mapping from float -> str for protected attributes and/or labels. If our use case differs from the default, we can modify the mapping stored in metadata:

```python
label_map = {1.0: 'Good Credit', 0.0: 'Bad Credit'}
protected_attribute_maps = [{1.0: 'Male', 0.0: 'Female'}]
gd = GermanDataset(
    protected_attribute_names=['sex'],
    privileged_classes=[['male']],
    metadata={'label_map': label_map, 'protected_attribute_maps': protected_attribute_maps}
)
```

> This information will stay attached to the dataset and can be used for more descriptive visualizations.

#### 5. aif360.datasets.LawSchoolGPADataset

**Class**: aif360.datasets.LawSchoolGPADataset(_dep_var_name='zfygpa', protected_attribute_names=['race'], privileged_classes=[['white']], instance_weights_name=None, categorical_features=[], na_values=[], custom_preprocessing=None, metadata=None_)


**Description**: Law School GPA dataset.

**Initialization**:
```python
__init__(dep_var_name='zfygpa', protected_attribute_names=['race'], privileged_classes=[['white']], instance_weights_name=None, categorical_features=[], na_values=[], custom_preprocessing=None, metadata=None)
```

**Parameters**:
- `dep_var_name` (str): Name of the dependent variable column in the dataset.
- `protected_attribute_names` (list): List of names corresponding to protected attribute columns in the dataset.
- `privileged_classes` (list(list)): Each element is a list of values which are considered privileged.
- `instance_weights_name` (str, optional): Name of the instance weights column in the dataset.
- `categorical_features` (list, optional): List of column names in the DataFrame to be expanded into one-hot vectors.
- `na_values` (list, optional): Additional strings to recognize as NA.
- `custom_preprocessing` (function, optional): A function object that acts on and returns a DataFrame. If `None`, no extra preprocessing is applied.
- `metadata` (dict, optional): Additional metadata to append.

**Methods**:

1. **`align_datasets`**: Align the other dataset features, labels, and protected attributes to this dataset.
   - **Parameters**: None.
   - **Returns**: None.

2. **`convert_to_dataframe`**: Convert the StructuredDataset to a pandas DataFrame.
   - **Parameters**:
     - `de_dummy_code` (bool, optional): Performs de-dummy coding, converting dummy-coded columns to categories. Default is `False`.
     - `sep` (char, optional): Separator between the prefix in the dummy indicators and the dummy-coded categorical levels. Default is `'='`.
     - `set_category` (bool, optional): Set the de-dummy coded features to categorical type. Default is `True`.
   - **Returns**:
     - `pandas.DataFrame`: Equivalent dataframe for the dataset.
     - `dict`: Attributes containing additional information pulled from the dataset, such as feature names, label names, protected attribute names, etc.

3. **`copy`**: Convenience method to return a copy of this dataset.
   - **Parameters**:
     - `deepcopy` (bool, optional): If `True`, performs a deep copy of the dataset. If `False`, performs a shallow copy. Default is `False`.
   - **Returns**:
     - `StructuredDataset`: A new dataset with fields copied from this object, and metadata set accordingly.

4. **`export_dataset`**: Export the dataset and supporting attributes (Preferred file format: HDF).
   - **Parameters**:
     - `export_metadata` (bool, optional): If `True`, export metadata along with the dataset. Default is `False`.
   - **Returns**: None.

5. **`import_dataset`**: Import the dataset and supporting attributes (Preferred file format: HDF).
   - **Parameters**:
     - `import_metadata` (bool, optional): If `True`, import metadata along with the dataset. Default is `False`.
   - **Returns**: None.

6. **`split`**: Split this dataset into multiple partitions.
   - **Parameters**:
     - `num_or_size_splits` (array or int): If an integer, it specifies the number of equal-sized folds to create. If an array of integers, it indicates the indices at which to split the dataset. If an array of floats (< 1), it represents fractional proportions at which to split the dataset.
     - `shuffle` (bool, optional): If `True`, randomly shuffle the dataset before splitting. Default is `False`.
     - `seed` (int or array_like, optional): Seed for random shuffling. Default is `None`.
   - **Returns**:
     - `list`: List of splits, each containing a dataset.

7. **`subset`**: Subset of dataset based on position.
   - **Parameters**:
     - `indexes` (iterable): Iterable containing row indexes to include in the subset.
   - **Returns**:
     - `StructuredDataset`: A subset of the dataset based on the provided indexes.

8. **`temporarily_ignore`**: Temporarily add the fields provided to ignore_fields.
   - **Parameters**:
     - `*fields` (str): Additional fields to ignore for equality comparison within the scope of the context manager.
   - **Returns**: None.

9. **`validate_dataset`**: Error checking and type validation.
   - **Parameters**: None.
   - **Returns**: None.

> This class represents the Law School GPA dataset and provides various methods for working with and analyzing the dataset, making it easier to perform fairness-related tasks and experiments.

##### 6. aif360.datasets.MEPSDataset19

**Class**: `aif360.datasets.MEPSDataset19` 
**Description**: MEPS Dataset.

**Initialization**:
```python
__init__(
    label_name='UTILIZATION',
    favorable_classes=[1.0],
    protected_attribute_names=['RACE'],
    privileged_classes=[['White']],
    instance_weights_name='PERWT15F',
    categorical_features=[
        'REGION', 'SEX', 'MARRY', 'FTSTU', 'ACTDTY', 'HONRDC', 'RTHLTH', 'MNHLTH',
        'HIBPDX', 'CHDDX', 'ANGIDX', 'MIDX', 'OHRTDX', 'STRKDX', 'EMPHDX', 'CHBRON',
        'CHOLDX', 'CANCERDX', 'DIABDX', 'JTPAIN', 'ARTHDX', 'ARTHTYPE', 'ASTHDX',
        'ADHDADDX', 'PREGNT', 'WLKLIM', 'ACTLIM', 'SOCLIM', 'COGLIM', 'DFHEAR42',
        'DFSEE42', 'ADSMOK42', 'PHQ242', 'EMPST', 'POVCAT', 'INSCOV'
    ],
    features_to_keep=[
        'REGION', 'AGE', 'SEX', 'RACE', 'MARRY', 'FTSTU', 'ACTDTY', 'HONRDC',
        'RTHLTH', 'MNHLTH', 'HIBPDX', 'CHDDX', 'ANGIDX', 'MIDX', 'OHRTDX', 'STRKDX',
        'EMPHDX', 'CHBRON', 'CHOLDX', 'CANCERDX', 'DIABDX', 'JTPAIN', 'ARTHDX',
        'ARTHTYPE', 'ASTHDX', 'ADHDADDX', 'PREGNT', 'WLKLIM', 'ACTLIM', 'SOCLIM',
        'COGLIM', 'DFHEAR42', 'DFSEE42', 'ADSMOK42', 'PCS42', 'MCS42', 'K6SUM42',
        'PHQ242', 'EMPST', 'POVCAT', 'INSCOV', 'UTILIZATION', 'PERWT15F'
    ],
    features_to_drop=[],
    na_values=[],
    custom_preprocessing=<function default_preprocessing>,
    metadata={
        'label_maps': [{1.0: '>= 10 Visits', 0.0: '< 10 Visits'}],
        'protected_attribute_maps': [{1.0: 'White', 0.0: 'Non-White'}]
    }
)
```

**Methods**:
1. **`align_datasets`**: Align the other dataset features, labels, and protected_attributes to this dataset.
   - **Parameters**: None.
   - **Returns**: None.

2. **`convert_to_dataframe`**: Convert the `StructuredDataset` to a pandas DataFrame.
   - **Parameters**:
     - `de_dummy_code` (*bool, optional*): Performs de-dummy coding, converting dummy-coded columns to categories. Default is `False`.
     - `sep` (*char, optional*): Separator between the prefix in the dummy indicators and the dummy-coded categorical levels. Default is `'='`.
     - `set_category` (*bool, optional*): Set the de-dummy coded features to categorical type. Default is `True`.
   - **Returns**:
     - `pandas.DataFrame`: Equivalent dataframe for the dataset.
     - `dict`: Attributes containing additional information pulled from the dataset, such as feature names, label names, protected attribute names, etc.

3. **`copy`**: Convenience method to return a copy of this dataset.
   - **Parameters**:
     - `deepcopy` (*bool, optional*): If `True`, performs a deep copy of the dataset. If `False`, performs a shallow copy. Default is `False`.
   - **Returns**:
     - `StructuredDataset`: A new dataset with fields copied from this object, and metadata set accordingly.

4. **`export_dataset`**: Export the dataset and supporting attributes (Preferred file format: HDF).
   - **Parameters**:
     - `export_metadata` (*bool, optional*): If `True`, export metadata along with the dataset. Default is `False`.
   - **Returns**: None.

5. **`import_dataset`**: Import the dataset and supporting attributes (Preferred file format: HDF).
   - **Parameters**:
     - `import_metadata` (*bool, optional*): If `True`, import metadata along with the dataset. Default is `False`.
   - **Returns**: None.

6. **`split`**: Split this dataset into multiple partitions.
   - **Parameters**:
     - `num_or_size_splits` (*array or int*): If an integer, it specifies the number of equal-sized folds to create. If an array of integers, it indicates the indices at which to split the dataset. If an array of floats (< 1), it represents fractional proportions at which to split the dataset.
     - `shuffle` (*bool, optional*): If `True`, randomly shuffle the dataset before splitting. Default is `False`.
     - `seed` (*int or array_like, optional*): Seed for random shuffling. Default is `None`.
   - **Returns**:
     - `list`: List of splits, each containing a dataset.

7. **`subset`**: Subset of dataset based on position.
   - **Parameters**:
     - `indexes` (*iterable*): Iterable containing row indexes to include in the subset.
   - **Returns**:
     - `StructuredDataset`: A subset of the dataset based on the provided indexes.

8. **`temporarily_ignore`**:Temporarily add the fields provided to ignore_fields.
   - **Parameters**:
     - `*fields` (*str*): Additional fields to ignore for equality comparison within the scope of the context manager.
   - **Returns**: None.

9. **`validate_dataset`**: Error checking and type validation.
   - **Parameters**: None.
   - **Returns**: None.



#### 7. aif360.datasets.MEPSDataset20


**Class**: `aif360.datasets.MEPSDataset20`
**Description**: MEPS Dataset.

**Initialization**:
```python
__init__(
    label_name='UTILIZATION',
    favorable_classes=[1.0],
    protected_attribute_names=['RACE'],
    privileged_classes=[['White']],
    instance_weights_name='PERWT15F',
    categorical_features=[
        'REGION', 'SEX', 'MARRY', 'FTSTU', 'ACTDTY', 'HONRDC', 'RTHLTH', 'MNHLTH', 'HIBPDX',
        'CHDDX', 'ANGIDX', 'MIDX', 'OHRTDX', 'STRKDX', 'EMPHDX', 'CHBRON', 'CHOLDX', 'CANCERDX',
        'DIABDX', 'JTPAIN', 'ARTHDX', 'ARTHTYPE', 'ASTHDX', 'ADHDADDX', 'PREGNT', 'WLKLIM',
        'ACTLIM', 'SOCLIM', 'COGLIM', 'DFHEAR42', 'DFSEE42', 'ADSMOK42', 'PHQ242', 'EMPST',
        'POVCAT', 'INSCOV'
    ],
    features_to_keep=[
        'REGION', 'AGE', 'SEX', 'RACE', 'MARRY', 'FTSTU', 'ACTDTY', 'HONRDC', 'RTHLTH', 'MNHLTH',
        'HIBPDX', 'CHDDX', 'ANGIDX', 'MIDX', 'OHRTDX', 'STRKDX', 'EMPHDX', 'CHBRON', 'CHOLDX',
        'CANCERDX', 'DIABDX', 'JTPAIN', 'ARTHDX', 'ARTHTYPE', 'ASTHDX', 'ADHDADDX', 'PREGNT',
        'WLKLIM', 'ACTLIM', 'SOCLIM', 'COGLIM', 'DFHEAR42', 'DFSEE42', 'ADSMOK42', 'PCS42',
        'MCS42', 'K6SUM42', 'PHQ242', 'EMPST', 'POVCAT', 'INSCOV', 'UTILIZATION', 'PERWT15F'
    ],
    features_to_drop=[],
    na_values=[],
    custom_preprocessing=<function default_preprocessing>,
    metadata={
        'label_maps': [{1.0: '>= 10 Visits', 0.0: '< 10 Visits'}],
        'protected_attribute_maps': [{1.0: 'White', 0.0: 'Non-White'}]
    }
)
```

**Parameters**:
- `label_name` (*str*): Name of the label column in the dataset.
- `favorable_classes` (*list*): List of favorable label values.
- `protected_attribute_names` (*list*): List of protected attribute column names.
- `privileged_classes` (*list*): List of privileged classes for protected attributes.
- `instance_weights_name` (*str*): Name of the instance weights column.
- `categorical_features` (*list*): List of categorical feature names.
- `features_to_keep` (*list*): List of feature names to keep.
- `features_to_drop` (*list*): List of feature names to drop.
- `na_values` (*list*): Additional NA values.
- `custom_preprocessing` (*function*): Custom preprocessing function.
- `metadata` (*dict*): Metadata about the dataset.

**Methods**:

1. **`align_datasets`**: This method aligns the other dataset's features, labels, and protected attributes to match with this dataset. It ensures that the two datasets have consistent structures for fair comparison and analysis.
   - **Parameters**: No additional parameters required.
   - **Returns**: None.

2. **`convert_to_dataframe`**: This method converts the `StructuredDataset` to a pandas DataFrame. It provides a convenient way to work with the dataset as a DataFrame for various data analysis tasks.
   - **Parameters**:
     - `de_dummy_code` (bool, optional): Performs de-dummy coding, converting dummy-coded columns to categories. Default is `False`.
     - `sep` (char, optional): Separator between the prefix in the dummy indicators and the dummy-coded categorical levels. Default is `'='`.
     - `set_category` (bool, optional): Set the de-dummy coded features to categorical type. Default is `True`.
   - **Returns**:
     - `pandas.DataFrame`: Equivalent dataframe for the dataset.
     - `dict`: Attributes containing additional information pulled from the dataset, such as feature names, label names, protected attribute names, etc.

3. **`copy`**: This is a convenience method to return a copy of the dataset. It allows you to create a duplicate of the dataset without modifying the original dataset.
   - **Parameters**:
     - `deepcopy` (bool, optional): If `True`, performs a deep copy of the dataset. If `False`, performs a shallow copy. Default is `False`.
   - **Returns**:
     - `StructuredDataset`: A new dataset with fields copied from this object, and metadata set accordingly.

4. **`export_dataset`**: This method allows you to export the dataset and its supporting attributes. The preferred file format for export is HDF.
   - **Parameters**:
     - `export_metadata` (bool, optional): If `True`, export metadata along with the dataset. Default is `False`.
   - **Returns**: None.

5. **`import_dataset`**: This method is used to import a dataset and its supporting attributes from a file. The preferred file format for import is HDF.
   - **Parameters**:
     - `import_metadata` (bool, optional): If `True`, import metadata along with the dataset. Default is `False`.
   - **Returns**: None.

6. **`split`**: This method splits the dataset into multiple partitions. It can be useful for tasks such as cross-validation.
   - **Parameters**:
     - `num_or_size_splits` (array or int): If an integer, it specifies the number of equal-sized folds to create. If an array of integers, it indicates the indices at which to split the dataset. If an array of floats (< 1), it represents fractional proportions at which to split the dataset.
     - `shuffle` (bool, optional): If `True`, randomly shuffle the dataset before splitting. Default is `False`.
     - `seed` (int or array_like, optional): Seed for random shuffling. Default is `None`.
   - **Returns**:
     - `list`: List of splits, each containing a dataset.

7. **`subset`**: This method creates a subset of the dataset based on specified row indexes. It allows you to select a subset of the data for analysis.
   - **Parameters**:
     - `indexes` (iterable): An iterable containing row indexes to include in the subset.
   - **Returns**:
     - `StructuredDataset`: A subset of the dataset based on the provided indexes.

8. **`temporarily_ignore`**: This method temporarily adds the provided fields to the list of fields to be ignored for equality comparisons. It is typically used within a context manager to ignore specific fields temporarily.
   - **Parameters**:
     - `*fields` (str): Additional fields to ignore for equality comparison within the scope of the context manager.
   - **Returns**: None.

9. **`validate_dataset`**:This method performs error checking and type validation on the dataset. It ensures that the dataset conforms to expected data types and structures.
   - **Parameters**: No additional parameters required.
   - **Returns**: None.

> These methods provide various functionalities for working with and analyzing the dataset, making it easier to perform fairness-related tasks and experiments.


#### 8. aif360.datasets.MEPSDataset21

**Class**: `aif360.datasets.MEPSDataset21`

**Description**:
MEPS Dataset.

**Initialization**:
```python
__init__(
    label_name='UTILIZATION',
    favorable_classes=[1.0],
    protected_attribute_names=['RACE'],
    privileged_classes=[['White']],
    instance_weights_name='PERWT16F',
    categorical_features=[
        'REGION', 'SEX', 'MARRY', 'FTSTU', 'ACTDTY', 'HONRDC', 'RTHLTH', 'MNHLTH',
        'HIBPDX', 'CHDDX', 'ANGIDX', 'MIDX', 'OHRTDX', 'STRKDX', 'EMPHDX', 'CHBRON',
        'CHOLDX', 'CANCERDX', 'DIABDX', 'JTPAIN', 'ARTHDX', 'ARTHTYPE', 'ASTHDX',
        'ADHDADDX', 'PREGNT', 'WLKLIM', 'ACTLIM', 'SOCLIM', 'COGLIM', 'DFHEAR42',
        'DFSEE42', 'ADSMOK42', 'PHQ242', 'EMPST', 'POVCAT', 'INSCOV'
    ],
    features_to_keep=[
        'REGION', 'AGE', 'SEX', 'RACE', 'MARRY', 'FTSTU', 'ACTDTY', 'HONRDC', 'RTHLTH',
        'MNHLTH', 'HIBPDX', 'CHDDX', 'ANGIDX', 'MIDX', 'OHRTDX', 'STRKDX', 'EMPHDX',
        'CHBRON', 'CHOLDX', 'CANCERDX', 'DIABDX', 'JTPAIN', 'ARTHDX', 'ARTHTYPE',
        'ASTHDX', 'ADHDADDX', 'PREGNT', 'WLKLIM', 'ACTLIM', 'SOCLIM', 'COGLIM',
        'DFHEAR42', 'DFSEE42', 'ADSMOK42', 'PCS42', 'MCS42', 'K6SUM42', 'PHQ242',
        'EMPST', 'POVCAT', 'INSCOV', 'UTILIZATION', 'PERWT16F'
    ],
    features_to_drop=[],
    na_values=[],
    custom_preprocessing=<function default_preprocessing>,
    metadata={
        'label_maps': [{1.0: '>= 10 Visits', 0.0: '< 10 Visits'}],
        'protected_attribute_maps': [{1.0: 'White', 0.0: 'Non-White'}]
    }
)
```

**Methods**:

1. **`align_datasets`**: Align the other dataset features, labels, and protected_attributes to this dataset.
   
   **Parameters**:- `other` (_StructuredDataset_) – Other dataset that needs to be aligned.
   
   **Returns**:- `StructuredDataset` – New aligned dataset.

2. **`convert_to_dataframe`**: Convert the StructuredDataset to a pandas.DataFrame.
   
   **Parameters**:
     - `de_dummy_code` (bool) – Performs de_dummy_coding, converting dummy-coded columns to categories. If de_dummy_code is True and this dataset contains mappings for label and/or protected attribute values to strings in the metadata, this method will convert those as well.
     - `sep` (char) – Separator between the prefix in the dummy indicators and the dummy-coded categorical levels.
     - `set_category` (bool) – Set the de-dummy coded features to categorical type.
   
    **Returns**:
     - `(pandas.DataFrame, dict)`:
       - `pandas.DataFrame`: Equivalent dataframe for a dataset. All columns will have only numeric values. The protected_attributes field in the dataset will override the values in the features field.
       - `dict`: Attributes. Will contain additional information pulled from the dataset such as feature_names, label_names, protected_attribute_names, instance_names, instance_weights, privileged_protected_attributes, unprivileged_protected_attributes. The metadata will not be returned.

3. **`copy`**: Convenience method to return a copy of this dataset.
   
   **Parameters**:- `deepcopy` (bool, optional) – deepcopy() this dataset if True, shallow copy otherwise.
   
   **Returns**:- `Dataset` – A new dataset with fields copied from this object and metadata set accordingly.

4. **`export_dataset`**: Export the dataset and supporting attributes. (The preferred file format is HDF)
   
   **Parameters**:- `export_metadata` (bool, optional) – If True, export metadata along with the dataset.
   
   **Returns**: None

5. **`import_dataset`**: Import the dataset and supporting attributes. (The preferred file format is HDF)
   
   **Parameters**:- `import_metadata` (bool, optional) – If True, import metadata along with the dataset.
   
   **Returns**: None

6. **`split`**: Split this dataset into multiple partitions.
   
   **Parameters**: - `num_or_size_splits` (_array or int_) – If num_or_size_splits is an int, k, the value is the number of equal-sized folds to make (if k does not evenly divide the dataset these folds are approximately equal-sized). If num_or_size_splits is an array of type int, the values are taken as the indices at which to split the dataset. If the values are floats (< 1.), they are considered to be fractional proportions

---
---






# Acknowledgments

This instructional document incorporates information and data from various sources, including the AIF360 library, AIF360 Github repository, and AIF360 Documentation. We would like to acknowledge and give credit to these sources for their valuable contributions to the content of this document.

- AIF360 Github Repository: [Link](https://github.com/Trusted-AI/AIF360)
- AIF360 Documentation: [Link](https://aif360.readthedocs.io/en/latest/index.html)

We express our gratitude to the creators, contributors, and maintainers of AIF360 for their dedication to fairness and bias mitigation in machine learning. Their resources have been instrumental in the development of this instructional material.
